{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "conceptual-season",
   "metadata": {},
   "source": [
    "We simulate a small amount of data from many individual FA models and then we fit the models together and alone and measure the benefit (in terms of the likelihood of held-out test data) of fitting the models together vs. fitting them together. \n",
    "\n",
    "\n",
    "For comparison, when fitting FA models individually we use a standard FA fitting package to estimate point estimates for model parameters.  When evaluating models that have been fit together, we use the modes of posterior distributions as point estimates. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "available-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "empty-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from janelia_core.ml.utils import list_torch_devices\n",
    "\n",
    "from probabilistic_model_synthesis.fa import FAMdl\n",
    "from probabilistic_model_synthesis.fa import Fitter\n",
    "from probabilistic_model_synthesis.fa import generate_basic_posteriors\n",
    "from probabilistic_model_synthesis.fa import generate_simple_prior_collection\n",
    "from probabilistic_model_synthesis.fa import VICollection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-documentary",
   "metadata": {},
   "source": [
    "## Parameters go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accompanied-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of individuals we simulate observing data from \n",
    "n_individuals = 10\n",
    "\n",
    "# Range of the number of variables we observe from each individual - the actual number of variables we observe from an\n",
    "# individual will be pulled uniformly from this range (inclusive)\n",
    "n_var_range = [100, 120]\n",
    "\n",
    "# Range of the number of samples we observe for fittig from each individual - the actual number we observe \n",
    "# from each individual will be unformly from this range (inclusive)\n",
    "n_fitting_smps_range = [10, 15]\n",
    "\n",
    "# Number of latent variables in the model\n",
    "n_latent_vars = 3\n",
    "\n",
    "# Number of samples we generate when testing each model\n",
    "n_test_smps = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-account",
   "metadata": {},
   "source": [
    "## Create the true prior distributions that relate parameters in the model to variable (e.g., neuron) properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interpreted-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_priors = generate_simple_prior_collection(n_prop_vars=2, n_latent_vars=n_latent_vars, \n",
    "                                               lm_mn_w_init_std=1.0, lm_std_w_init_std=.1,\n",
    "                                               mn_mn_w_init_std=1.0, mn_std_w_init_std=1.0,\n",
    "                                               psi_conc_f_w_init_std=2.0, psi_rate_f_w_init_std=1.0, \n",
    "                                               psi_conc_bias_mn=10.0, psi_rate_bias_mn=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-trader",
   "metadata": {},
   "source": [
    "## Generate properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tribal-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_n_vars = np.random.randint(n_var_range[0], n_var_range[1]+1, n_individuals)\n",
    "ind_n_smps = np.random.randint(n_fitting_smps_range[0], n_fitting_smps_range[1]+1, n_individuals)\n",
    "ind_props = [torch.rand(size=[n_vars,2]) for n_vars in ind_n_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-optimum",
   "metadata": {},
   "source": [
    "## Generate true FA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "continuing-conditions",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ind_true_fa_mdls = [FAMdl(lm=true_priors.lm_prior.sample(props), mn=true_priors.mn_prior.sample(props).squeeze(), \n",
    "                           psi=(true_priors.psi_prior.sample(props).squeeze()))\n",
    "                        for props in ind_props]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-broadway",
   "metadata": {},
   "source": [
    "## Generate data for fitting from each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "considered-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ind_train_data = [mdl.sample(n_smps) for n_smps, mdl in zip(ind_n_smps, ind_true_fa_mdls)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-proposal",
   "metadata": {},
   "source": [
    "## Fit FA models together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0f53f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 GPUs\n"
     ]
    }
   ],
   "source": [
    "devices, _ = list_torch_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "proof-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_priors = generate_simple_prior_collection(n_prop_vars=2, n_latent_vars=n_latent_vars)\n",
    "\n",
    "fit_posteriors = generate_basic_posteriors(n_obs_vars=ind_n_vars, n_smps=ind_n_smps, n_latent_vars=n_latent_vars)\n",
    "\n",
    "fit_mdls = [FAMdl(lm=None, mn=None, psi=None) for i in range(n_individuals)]\n",
    "\n",
    "vi_collections = [VICollection(data=data_i[1], props=props_i, mdl=mdl_i, posteriors=posteriors_i) \n",
    "                  for data_i, props_i,mdl_i, posteriors_i in zip(ind_train_data, ind_props, fit_mdls, fit_posteriors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "protected-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = Fitter(vi_collections=vi_collections, priors=fit_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3471bbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.distribute(distribute_data=True, devices=devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "legal-waterproof",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== EPOCH 0 COMPLETE ===========\n",
      "Obj: 1.12e+05\n",
      "----------------------------------------\n",
      "NELL: 6.63e+03, 9.74e+03, 1.61e+04, 9.90e+03, 1.53e+04, 1.03e+04, 8.47e+03, 1.80e+04, 1.11e+04, 7.76e+03\n",
      "Latent KL: 5.10e-01, 4.41e-01, 2.22e-01, 3.23e-01, 2.73e-01, 3.23e-01, 6.84e-01, 5.46e-01, 3.78e-01, 2.62e-01\n",
      "LM KL: 5.75e+02, 6.19e+02, 6.04e+02, 6.24e+02, 6.72e+02, 5.80e+02, 5.52e+02, 5.10e+02, 6.01e+02, 6.37e+02\n",
      "Mn KL: 2.22e+02, 2.20e+02, 2.06e+02, 2.02e+02, 2.09e+02, 2.01e+02, 1.92e+02, 1.71e+02, 2.12e+02, 2.17e+02\n",
      "Psi KL: 2.37e+01, 2.45e+01, 2.46e+01, 2.38e+01, 2.48e+01, 2.24e+01, 2.18e+01, 2.12e+01, 2.44e+01, 2.52e+01\n",
      "----------------------------------------\n",
      "LR: 0.1\n",
      "Elapsed time (secs): 2.4620072841644287\n",
      "----------------------------------------\n",
      "CPU cur memory used (GB): 4.53e+00\n",
      "GPU_0 cur memory used (GB): 1.79e-04, max memory used (GB): 1.79e-04\n",
      "GPU_1 cur memory used (GB): 1.09e-04, max memory used (GB): 1.09e-04\n",
      "GPU_2 cur memory used (GB): 1.11e-04, max memory used (GB): 1.11e-04\n",
      "\n",
      "=========== EPOCH 100 COMPLETE ===========\n",
      "Obj: 3.16e+04\n",
      "----------------------------------------\n",
      "NELL: 2.79e+03, 2.61e+03, 2.94e+03, 2.68e+03, 2.38e+03, 2.50e+03, 2.89e+03, 2.80e+03, 3.10e+03, 2.15e+03\n",
      "Latent KL: 6.97e+01, 7.14e+01, 9.18e+01, 6.19e+01, 8.88e+01, 7.71e+01, 7.08e+01, 8.36e+01, 7.31e+01, 5.28e+01\n",
      "LM KL: 2.17e+02, 2.48e+02, 4.46e+02, 1.87e+02, 3.75e+02, 2.15e+02, 1.82e+02, 2.98e+02, 2.14e+02, 1.65e+02\n",
      "Mn KL: 1.29e+02, 1.26e+02, 1.19e+02, 1.33e+02, 1.33e+02, 1.36e+02, 1.26e+02, 1.06e+02, 1.25e+02, 1.18e+02\n",
      "Psi KL: 1.25e+01, 1.08e+01, 1.55e+01, 1.29e+01, 9.65e+00, 1.04e+01, 1.47e+01, 1.32e+01, 1.75e+01, 1.35e+01\n",
      "----------------------------------------\n",
      "LR: 0.010000000000000002\n",
      "Elapsed time (secs): 27.08662724494934\n",
      "----------------------------------------\n",
      "CPU cur memory used (GB): 4.53e+00\n",
      "GPU_0 cur memory used (GB): 1.79e-04, max memory used (GB): 1.79e-04\n",
      "GPU_1 cur memory used (GB): 1.09e-04, max memory used (GB): 1.09e-04\n",
      "GPU_2 cur memory used (GB): 1.11e-04, max memory used (GB): 1.11e-04\n",
      "\n",
      "=========== EPOCH 200 COMPLETE ===========\n",
      "Obj: 3.07e+04\n",
      "----------------------------------------\n",
      "NELL: 2.78e+03, 2.52e+03, 2.88e+03, 2.65e+03, 2.36e+03, 2.48e+03, 2.80e+03, 2.80e+03, 3.03e+03, 2.12e+03\n",
      "Latent KL: 7.01e+01, 6.97e+01, 9.35e+01, 7.26e+01, 7.40e+01, 8.40e+01, 7.43e+01, 8.90e+01, 7.95e+01, 6.40e+01\n",
      "LM KL: 1.36e+02, 1.95e+02, 4.11e+02, 1.36e+02, 3.04e+02, 1.65e+02, 1.47e+02, 2.51e+02, 1.70e+02, 1.07e+02\n",
      "Mn KL: 1.21e+02, 1.20e+02, 1.14e+02, 1.27e+02, 1.21e+02, 1.31e+02, 1.22e+02, 1.02e+02, 1.22e+02, 1.12e+02\n",
      "Psi KL: 1.28e+01, 1.18e+01, 1.56e+01, 1.27e+01, 9.78e+00, 1.10e+01, 1.45e+01, 1.40e+01, 1.86e+01, 1.42e+01\n",
      "----------------------------------------\n",
      "LR: 0.010000000000000002\n",
      "Elapsed time (secs): 51.60847496986389\n",
      "----------------------------------------\n",
      "CPU cur memory used (GB): 4.53e+00\n",
      "GPU_0 cur memory used (GB): 1.79e-04, max memory used (GB): 1.79e-04\n",
      "GPU_1 cur memory used (GB): 1.09e-04, max memory used (GB): 1.09e-04\n",
      "GPU_2 cur memory used (GB): 1.11e-04, max memory used (GB): 1.11e-04\n",
      "\n",
      "=========== EPOCH 300 COMPLETE ===========\n",
      "Obj: 2.99e+04\n",
      "----------------------------------------\n",
      "NELL: 2.81e+03, 2.49e+03, 2.86e+03, 2.62e+03, 2.39e+03, 2.44e+03, 2.80e+03, 2.77e+03, 3.00e+03, 2.07e+03\n",
      "Latent KL: 7.29e+01, 7.48e+01, 9.53e+01, 7.55e+01, 8.04e+01, 8.19e+01, 6.97e+01, 8.83e+01, 7.93e+01, 6.30e+01\n",
      "LM KL: 8.91e+01, 1.58e+02, 3.78e+02, 1.04e+02, 2.50e+02, 1.32e+02, 1.31e+02, 2.15e+02, 1.32e+02, 7.37e+01\n",
      "Mn KL: 1.22e+02, 1.22e+02, 1.19e+02, 1.30e+02, 1.23e+02, 1.31e+02, 1.25e+02, 1.05e+02, 1.24e+02, 1.15e+02\n",
      "Psi KL: 1.34e+01, 1.33e+01, 1.71e+01, 1.35e+01, 1.08e+01, 1.20e+01, 1.54e+01, 1.55e+01, 1.94e+01, 1.63e+01\n",
      "----------------------------------------\n",
      "LR: 0.010000000000000002\n",
      "Elapsed time (secs): 76.4248526096344\n",
      "----------------------------------------\n",
      "CPU cur memory used (GB): 4.53e+00\n",
      "GPU_0 cur memory used (GB): 1.79e-04, max memory used (GB): 1.79e-04\n",
      "GPU_1 cur memory used (GB): 1.09e-04, max memory used (GB): 1.09e-04\n",
      "GPU_2 cur memory used (GB): 1.11e-04, max memory used (GB): 1.11e-04\n",
      "\n",
      "=========== EPOCH 400 COMPLETE ===========\n",
      "Obj: 2.97e+04\n",
      "----------------------------------------\n",
      "NELL: 2.79e+03, 2.52e+03, 2.84e+03, 2.60e+03, 2.37e+03, 2.43e+03, 2.75e+03, 2.74e+03, 3.01e+03, 2.11e+03\n",
      "Latent KL: 7.25e+01, 7.22e+01, 9.11e+01, 7.60e+01, 7.74e+01, 7.59e+01, 7.35e+01, 8.59e+01, 8.76e+01, 6.23e+01\n",
      "LM KL: 5.35e+01, 1.08e+02, 3.05e+02, 7.66e+01, 2.03e+02, 8.66e+01, 1.04e+02, 1.72e+02, 8.99e+01, 3.97e+01\n",
      "Mn KL: 1.23e+02, 1.23e+02, 1.26e+02, 1.31e+02, 1.26e+02, 1.32e+02, 1.26e+02, 1.06e+02, 1.28e+02, 1.16e+02\n",
      "Psi KL: 1.45e+01, 1.48e+01, 1.80e+01, 1.50e+01, 1.20e+01, 1.33e+01, 1.62e+01, 1.66e+01, 2.08e+01, 1.78e+01\n",
      "----------------------------------------\n",
      "LR: 0.010000000000000002\n",
      "Elapsed time (secs): 101.17999458312988\n",
      "----------------------------------------\n",
      "CPU cur memory used (GB): 4.53e+00\n",
      "GPU_0 cur memory used (GB): 1.79e-04, max memory used (GB): 1.79e-04\n",
      "GPU_1 cur memory used (GB): 1.09e-04, max memory used (GB): 1.09e-04\n",
      "GPU_2 cur memory used (GB): 1.11e-04, max memory used (GB): 1.11e-04\n",
      "\n",
      "=========== EPOCH 500 COMPLETE ===========\n",
      "Obj: 2.90e+04\n",
      "----------------------------------------\n",
      "NELL: 2.77e+03, 2.52e+03, 2.83e+03, 2.60e+03, 2.33e+03, 2.42e+03, 2.73e+03, 2.71e+03, 3.00e+03, 2.06e+03\n",
      "Latent KL: 7.64e+01, 7.41e+01, 9.04e+01, 7.53e+01, 6.79e+01, 7.74e+01, 6.94e+01, 8.74e+01, 8.95e+01, 6.53e+01\n",
      "LM KL: 3.37e+01, 7.02e+01, 2.47e+02, 5.78e+01, 1.74e+02, 5.20e+01, 8.42e+01, 1.38e+02, 5.77e+01, 2.27e+01\n",
      "Mn KL: 1.25e+02, 1.24e+02, 1.25e+02, 1.33e+02, 1.27e+02, 1.33e+02, 1.26e+02, 1.09e+02, 1.30e+02, 1.16e+02\n",
      "Psi KL: 1.61e+01, 1.62e+01, 1.95e+01, 1.52e+01, 1.39e+01, 1.45e+01, 1.69e+01, 1.82e+01, 2.20e+01, 2.02e+01\n",
      "----------------------------------------\n",
      "LR: 0.010000000000000002\n",
      "Elapsed time (secs): 125.81292724609375\n",
      "----------------------------------------\n",
      "CPU cur memory used (GB): 4.53e+00\n",
      "GPU_0 cur memory used (GB): 1.79e-04, max memory used (GB): 1.79e-04\n",
      "GPU_1 cur memory used (GB): 1.09e-04, max memory used (GB): 1.09e-04\n",
      "GPU_2 cur memory used (GB): 1.11e-04, max memory used (GB): 1.11e-04\n",
      "\n",
      "=========== EPOCH 600 COMPLETE ===========\n",
      "Obj: 2.91e+04\n",
      "----------------------------------------\n",
      "NELL: 2.77e+03, 2.52e+03, 2.85e+03, 2.60e+03, 2.35e+03, 2.41e+03, 2.75e+03, 2.73e+03, 2.99e+03, 2.06e+03\n",
      "Latent KL: 7.71e+01, 7.16e+01, 8.86e+01, 7.88e+01, 6.82e+01, 7.79e+01, 7.52e+01, 8.13e+01, 8.81e+01, 5.92e+01\n",
      "LM KL: 2.77e+01, 4.81e+01, 2.12e+02, 4.61e+01, 1.54e+02, 3.47e+01, 6.31e+01, 1.19e+02, 4.49e+01, 1.81e+01\n",
      "Mn KL: 1.25e+02, 1.24e+02, 1.29e+02, 1.34e+02, 1.27e+02, 1.34e+02, 1.27e+02, 1.12e+02, 1.33e+02, 1.20e+02\n",
      "Psi KL: 1.76e+01, 1.76e+01, 2.11e+01, 1.64e+01, 1.55e+01, 1.54e+01, 1.78e+01, 1.98e+01, 2.31e+01, 2.18e+01\n",
      "----------------------------------------\n",
      "LR: 0.010000000000000002\n",
      "Elapsed time (secs): 150.2572410106659\n",
      "----------------------------------------\n",
      "CPU cur memory used (GB): 4.53e+00\n",
      "GPU_0 cur memory used (GB): 1.79e-04, max memory used (GB): 1.79e-04\n",
      "GPU_1 cur memory used (GB): 1.09e-04, max memory used (GB): 1.09e-04\n",
      "GPU_2 cur memory used (GB): 1.11e-04, max memory used (GB): 1.11e-04\n",
      "\n",
      "=========== EPOCH 700 COMPLETE ===========\n",
      "Obj: 2.88e+04\n",
      "----------------------------------------\n",
      "NELL: 2.73e+03, 2.51e+03, 2.79e+03, 2.59e+03, 2.35e+03, 2.37e+03, 2.77e+03, 2.71e+03, 2.98e+03, 2.07e+03\n",
      "Latent KL: 7.80e+01, 7.42e+01, 8.60e+01, 7.72e+01, 7.07e+01, 8.19e+01, 7.41e+01, 8.13e+01, 8.65e+01, 5.81e+01\n",
      "LM KL: 2.84e+01, 3.47e+01, 1.79e+02, 4.30e+01, 1.36e+02, 2.63e+01, 4.89e+01, 9.84e+01, 3.69e+01, 1.56e+01\n",
      "Mn KL: 1.25e+02, 1.24e+02, 1.31e+02, 1.32e+02, 1.30e+02, 1.35e+02, 1.28e+02, 1.11e+02, 1.32e+02, 1.20e+02\n",
      "Psi KL: 1.86e+01, 1.93e+01, 2.19e+01, 1.70e+01, 1.71e+01, 1.66e+01, 1.88e+01, 2.09e+01, 2.43e+01, 2.31e+01\n",
      "----------------------------------------\n",
      "LR: 0.010000000000000002\n",
      "Elapsed time (secs): 174.73680591583252\n",
      "----------------------------------------\n",
      "CPU cur memory used (GB): 4.53e+00\n",
      "GPU_0 cur memory used (GB): 1.79e-04, max memory used (GB): 1.79e-04\n",
      "GPU_1 cur memory used (GB): 1.09e-04, max memory used (GB): 1.09e-04\n",
      "GPU_2 cur memory used (GB): 1.11e-04, max memory used (GB): 1.11e-04\n",
      "\n",
      "=========== EPOCH 800 COMPLETE ===========\n",
      "Obj: 2.86e+04\n",
      "----------------------------------------\n",
      "NELL: 2.76e+03, 2.48e+03, 2.80e+03, 2.61e+03, 2.34e+03, 2.40e+03, 2.71e+03, 2.73e+03, 2.99e+03, 2.06e+03\n",
      "Latent KL: 7.44e+01, 7.27e+01, 8.82e+01, 7.52e+01, 7.22e+01, 7.83e+01, 7.72e+01, 8.25e+01, 8.52e+01, 5.73e+01\n",
      "LM KL: 3.02e+01, 2.71e+01, 1.48e+02, 4.17e+01, 1.17e+02, 1.98e+01, 4.01e+01, 8.12e+01, 3.47e+01, 1.36e+01\n",
      "Mn KL: 1.24e+02, 1.25e+02, 1.32e+02, 1.33e+02, 1.29e+02, 1.36e+02, 1.29e+02, 1.12e+02, 1.33e+02, 1.18e+02\n",
      "Psi KL: 1.99e+01, 2.04e+01, 2.29e+01, 1.74e+01, 1.86e+01, 1.77e+01, 1.94e+01, 2.21e+01, 2.48e+01, 2.38e+01\n",
      "----------------------------------------\n",
      "LR: 0.010000000000000002\n",
      "Elapsed time (secs): 199.37701225280762\n",
      "----------------------------------------\n",
      "CPU cur memory used (GB): 4.53e+00\n",
      "GPU_0 cur memory used (GB): 1.79e-04, max memory used (GB): 1.79e-04\n",
      "GPU_1 cur memory used (GB): 1.09e-04, max memory used (GB): 1.09e-04\n",
      "GPU_2 cur memory used (GB): 1.11e-04, max memory used (GB): 1.11e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== EPOCH 900 COMPLETE ===========\n",
      "Obj: 2.85e+04\n",
      "----------------------------------------\n",
      "NELL: 2.76e+03, 2.48e+03, 2.80e+03, 2.60e+03, 2.35e+03, 2.40e+03, 2.76e+03, 2.69e+03, 2.98e+03, 2.05e+03\n",
      "Latent KL: 7.28e+01, 7.46e+01, 9.00e+01, 7.33e+01, 6.99e+01, 7.95e+01, 8.03e+01, 8.26e+01, 8.46e+01, 6.01e+01\n",
      "LM KL: 3.17e+01, 2.51e+01, 1.14e+02, 3.82e+01, 9.68e+01, 1.88e+01, 3.50e+01, 6.65e+01, 3.01e+01, 1.38e+01\n",
      "Mn KL: 1.26e+02, 1.26e+02, 1.32e+02, 1.33e+02, 1.32e+02, 1.36e+02, 1.27e+02, 1.12e+02, 1.32e+02, 1.20e+02\n",
      "Psi KL: 2.04e+01, 2.11e+01, 2.37e+01, 1.84e+01, 1.98e+01, 1.82e+01, 1.97e+01, 2.31e+01, 2.54e+01, 2.50e+01\n",
      "----------------------------------------\n",
      "LR: 0.010000000000000002\n",
      "Elapsed time (secs): 223.74925136566162\n",
      "----------------------------------------\n",
      "CPU cur memory used (GB): 4.53e+00\n",
      "GPU_0 cur memory used (GB): 1.79e-04, max memory used (GB): 1.79e-04\n",
      "GPU_1 cur memory used (GB): 1.09e-04, max memory used (GB): 1.09e-04\n",
      "GPU_2 cur memory used (GB): 1.11e-04, max memory used (GB): 1.11e-04\n"
     ]
    }
   ],
   "source": [
    "logs = [fitter.fit(1000, milestones=[100], update_int=100, init_lr=.1, skip_lm_kl=False, \n",
    "                 skip_mn_kl=False, skip_psi_kl=False) for fit_r in range(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a19da19",
   "metadata": {},
   "source": [
    "## Move combined models to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63d651a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.distribute(devices=[torch.device('cpu')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-subscription",
   "metadata": {},
   "source": [
    "## Fit FA models individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "breeding-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "alone_models = [None]*n_individuals\n",
    "for ind_i in range(n_individuals):\n",
    "    mdl = sklearn.decomposition.FactorAnalysis(n_components=n_latent_vars)\n",
    "    mdl.fit(ind_train_data[ind_i][1].numpy())\n",
    "    alone_models[ind_i] = mdl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-default",
   "metadata": {},
   "source": [
    "## Measure performance of the fit models on new test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "judicial-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ind_test_data = [mdl.sample(n_test_smps) for mdl in ind_true_fa_mdls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "instant-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_test_ll = [None]*n_individuals\n",
    "with torch.no_grad():\n",
    "    eval_mdl = FAMdl() # Model object we ust just for evaluation \n",
    "    for ind_i in range(n_individuals):\n",
    "    \n",
    "        mdl_test_data = ind_test_data[ind_i][1]\n",
    "        \n",
    "        # Calculate log-likelihood using model fit alone\n",
    "        \n",
    "        alone_lm = torch.tensor(alone_models[ind_i].components_.transpose())\n",
    "        alone_mn = torch.tensor(alone_models[ind_i].mean_)\n",
    "        alone_psi = torch.tensor(alone_models[ind_i].noise_variance_)\n",
    "    \n",
    "        alone_ll = torch.sum(eval_mdl.log_prob(x=mdl_test_data, lm=alone_lm, mn=alone_mn, psi=alone_psi))\n",
    "        alone_ll = (alone_ll/n_test_smps).numpy().item()\n",
    "        \n",
    "        # Calculate log-likelihood using model fit with the other models\n",
    "        \n",
    "        comb_lm = vi_collections[ind_i].posteriors.lm_post(ind_props[ind_i])\n",
    "        comb_mn = vi_collections[ind_i].posteriors.mn_post(ind_props[ind_i]).squeeze()\n",
    "        comb_psi = vi_collections[ind_i].posteriors.psi_post.mode(ind_props[ind_i]).squeeze()\n",
    "                             \n",
    "        comb_ll = torch.sum(eval_mdl.log_prob(x=mdl_test_data, lm=comb_lm, mn=comb_mn, psi=comb_psi))\n",
    "        comb_ll = (comb_ll/n_test_smps).numpy().item()\n",
    "        \n",
    "        ind_test_ll[ind_i] = {'alone': alone_ll, 'comb': comb_ll}\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "solved-columbia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'alone': -273.84177291126724, 'comb': -209.60745239257812},\n",
       " {'alone': -321.52913658438297, 'comb': -222.1905059814453},\n",
       " {'alone': -253.67458512634033, 'comb': -211.0919952392578},\n",
       " {'alone': -273.76329503560646, 'comb': -214.62393188476562},\n",
       " {'alone': -309.88419375405914, 'comb': -225.42991638183594},\n",
       " {'alone': -248.20801485929906, 'comb': -198.0729217529297},\n",
       " {'alone': -225.41397381433777, 'comb': -195.1164093017578},\n",
       " {'alone': -235.4733753351554, 'comb': -189.27928161621094},\n",
       " {'alone': -250.53135460611054, 'comb': -213.1034393310547},\n",
       " {'alone': -350.83425068866603, 'comb': -218.47979736328125}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_test_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9178812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
