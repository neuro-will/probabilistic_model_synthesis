{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "minus-conditioning",
   "metadata": {},
   "source": [
    "Here we synthesize Gaussian non-linear dimensionality reduction models across conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "naval-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adequate-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import Identity\n",
    "\n",
    "from janelia_core.math.basic_functions import optimal_orthonormal_transform\n",
    "from janelia_core.ml.extra_torch_modules import ConstantRealFcn\n",
    "from janelia_core.ml.extra_torch_modules import DenseLNLNet\n",
    "from janelia_core.ml.extra_torch_modules import PWLNNFcn\n",
    "from janelia_core.ml.extra_torch_modules import QuadSurf\n",
    "from janelia_core.ml.utils import list_torch_devices\n",
    "from janelia_core.ml.utils import torch_mod_to_fcn\n",
    "from janelia_core.visualization.image_generation import generate_2d_fcn_image\n",
    "from janelia_core.visualization.matrix_visualization import cmp_n_mats\n",
    "\n",
    "from probabilistic_model_synthesis.gaussian_nonlinear_dim_reduction import align_intermediate_spaces\n",
    "from probabilistic_model_synthesis.gaussian_nonlinear_dim_reduction import compare_mean_and_lm_dists\n",
    "from probabilistic_model_synthesis.gaussian_nonlinear_dim_reduction import Fitter\n",
    "from probabilistic_model_synthesis.gaussian_nonlinear_dim_reduction import GNLDRMdl\n",
    "from probabilistic_model_synthesis.gaussian_nonlinear_dim_reduction import generate_basic_posteriors\n",
    "from probabilistic_model_synthesis.gaussian_nonlinear_dim_reduction import generate_hypercube_prior_collection\n",
    "from probabilistic_model_synthesis.gaussian_nonlinear_dim_reduction import generate_simple_prior_collection\n",
    "from probabilistic_model_synthesis.gaussian_nonlinear_dim_reduction import VICollection\n",
    "from probabilistic_model_synthesis.math import MeanFcnTransformer\n",
    "from probabilistic_model_synthesis.math import StdFcnTransformer\n",
    "from probabilistic_model_synthesis.visualization import assign_colors_to_pts\n",
    "from probabilistic_model_synthesis.visualization import plot_three_dim_pts\n",
    "from probabilistic_model_synthesis.visualization import plot_torch_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reserved-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-accreditation",
   "metadata": {},
   "source": [
    "## Parameters go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "typical-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of individuals we simulate observing data from \n",
    "n_individuals = 5\n",
    "\n",
    "# Range of the number of variables we observe from each individual - the actual number of variables we observe from an\n",
    "# individual will be pulled uniformly from this range (inclusive)\n",
    "n_var_range = [100, 120]\n",
    "\n",
    "# Range of the numbe0 of samples we observe from each individual - the actual number we observe from each individual\n",
    "# will be unformly from this range (inclusive)\n",
    "n_smps_range = [10000, 15000]\n",
    "\n",
    "# Number of latent variables in the model\n",
    "n_latent_vars = 2\n",
    "\n",
    "# True if we should use GPUs for fitting if they are available\n",
    "use_gpus = True\n",
    "\n",
    "# Parameters for the true scales\n",
    "s_mn = 1.0\n",
    "s_std = .0001\n",
    "\n",
    "# Parameters for generating shared m-module we use for fitting\n",
    "m_n_layers = 2 #2\n",
    "m_growth_rate = 2 #2\n",
    "n_intermediate_latent_vars = 3 #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "infectious-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine which devices we use for fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "living-shuttle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPUs found.\n"
     ]
    }
   ],
   "source": [
    "if use_gpus:\n",
    "    devices, _ = list_torch_devices()\n",
    "else:\n",
    "    devices = [torch.device('cpu')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-mission",
   "metadata": {},
   "source": [
    "## Create the true prior distributions that relate parameters in the model to variable (e.g., neuron) properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "traditional-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_true = QuadSurf(torch.tensor([.5, .5]), torch.tensor([.2, -.2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "common-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_priors = generate_hypercube_prior_collection(n_intermediate_latent_vars=n_intermediate_latent_vars,\n",
    "                                                  hc_params = {'n_divisions_per_dim': [10, 10], \n",
    "                                                               'dim_ranges': np.asarray([[-.1, 1.1], \n",
    "                                                                                         [-.1, 1.1]]),\n",
    "                                                               'n_div_per_hc_side_per_dim': [1, 1]},\n",
    "                                                  psi_rate_vl_init=1,\n",
    "                                               s_mn=s_mn, s_std=s_std)\n",
    "\n",
    "for d in range(n_intermediate_latent_vars):\n",
    "    true_priors.lm_prior.dists[d].mn_f.b_m.data[:] = torch.randn(true_priors.lm_prior.dists[d].mn_f.b_m.data.shape)\n",
    "    true_priors.mn_prior.mn_f.b_m.data[:] = 1*torch.randn(true_priors.mn_prior.mn_f.b_m.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-questionnaire",
   "metadata": {},
   "source": [
    "## Generate properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tight-ideal",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_n_vars = np.random.randint(n_var_range[0], n_var_range[1]+1, n_individuals)\n",
    "ind_props = [torch.rand(size=[n_vars,2]) for n_vars in ind_n_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-resistance",
   "metadata": {},
   "source": [
    "## Generate true models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "brave-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ind_true_mdls = [GNLDRMdl(n_latent_vars=n_latent_vars, m = m_true,\n",
    "                              lm=true_priors.lm_prior.form_standard_sample(true_priors.lm_prior.sample(props)), \n",
    "                              mn=true_priors.mn_prior.sample(props).squeeze(), \n",
    "                              psi=(true_priors.psi_prior.sample(props).squeeze()), \n",
    "                              s=true_priors.s_prior.sample(props).squeeze())\n",
    "                        for props in ind_props]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-camcorder",
   "metadata": {},
   "source": [
    "## Generate data from each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "focal-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_n_smps = np.random.randint(n_smps_range[0], n_smps_range[1]+1, n_individuals)\n",
    "with torch.no_grad():\n",
    "    ind_data = [mdl.sample(n_smps) for n_smps, mdl in zip(ind_n_smps, ind_true_mdls)]\n",
    "    \n",
    "# Now pair down the data for each model so that data from differents part of the latent space are observed in \n",
    "# each model\n",
    "\n",
    "ind_ang_range = 360/n_individuals\n",
    "for i in range(n_individuals):\n",
    "    cur_start_ang = i*ind_ang_range\n",
    "    cur_end_ang = (i+1)*ind_ang_range\n",
    "    \n",
    "    angles = np.asarray([math.degrees(math.atan2(p[0], p[1])) for p in ind_data[i][0]]) + 180\n",
    "    keep_pts = np.logical_and(angles > cur_start_ang, angles < cur_end_ang)  \n",
    "    \n",
    "    ind_data[i] = (ind_data[i][0][keep_pts, :], ind_data[i][1][keep_pts, :])\n",
    "\n",
    "# Update number of samples we actually have for each subject\n",
    "ind_n_smps = [data[0].shape[0] for data in ind_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-child",
   "metadata": {},
   "source": [
    "## Setup everything for fitting sp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beginning-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_m_fit = torch.nn.Sequential(DenseLNLNet(nl_class=torch.nn.ReLU, \n",
    "                                         d_in=n_latent_vars, \n",
    "                                         n_layers=m_n_layers, \n",
    "                                         growth_rate=m_growth_rate, \n",
    "                                         bias=True), \n",
    "                             torch.nn.Linear(in_features=n_latent_vars+m_n_layers*m_growth_rate, \n",
    "                                             out_features=n_intermediate_latent_vars, \n",
    "                                             bias=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "certain-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_priors = generate_hypercube_prior_collection(n_intermediate_latent_vars=n_intermediate_latent_vars,\n",
    "                                                  hc_params = {'n_divisions_per_dim': [10, 10], \n",
    "                                                               'dim_ranges': np.asarray([[-.1, 1.1], \n",
    "                                                                                         [-.1, 1.1]]),\n",
    "                                                               'n_div_per_hc_side_per_dim': [1, 1]},\n",
    "                                               s_mn=s_mn, s_std=s_std)\n",
    "    \n",
    "sp_posteriors = generate_basic_posteriors(n_obs_vars=ind_n_vars, n_smps=ind_n_smps, n_latent_vars=n_latent_vars, \n",
    "                                          n_intermediate_latent_vars=n_intermediate_latent_vars,\n",
    "                                           s_opts={'mn_mn': 1.0, 'mn_std': .00000001, 'std_iv': .0001})\n",
    "\n",
    "sp_fit_mdls = [GNLDRMdl(n_latent_vars=n_latent_vars, m=sp_m_fit, lm=None, mn=None, psi=None, s=None) \n",
    "               for i in range(n_individuals)]\n",
    "                    \n",
    "                                    \n",
    "sp_vi_collections = [VICollection(data=ind_data[s_i][1], \n",
    "                                  props=ind_props[s_i],\n",
    "                                  mdl = sp_fit_mdls[s_i],\n",
    "                                  posteriors = sp_posteriors[s_i]) for s_i in range(n_individuals)]\n",
    "\n",
    "for vi_coll in sp_vi_collections:\n",
    "    vi_coll.posteriors.lm_post = sp_priors.lm_prior\n",
    "    vi_coll.posteriors.mn_post = sp_priors.mn_prior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-tracker",
   "metadata": {},
   "source": [
    "## Fit the sp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "statewide-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_fitter = Fitter(vi_collections=sp_vi_collections, priors=sp_priors, devices=devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-oxide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== EPOCH 0 COMPLETE ===========\n",
      "Obj: 1.52e+08\n",
      "----------------------------------------\n",
      "NELL: 1.68e+06, 2.00e+06, 2.49e+06, 2.27e+06, 2.11e+06\n",
      "Latent KL: 4.91e+01, 5.52e+01, 6.13e+01, 5.78e+01, 5.31e+01\n",
      "LM KL: 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00\n",
      "Mn KL: 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00\n",
      "Psi KL: 2.76e+01, 3.01e+01, 3.28e+01, 3.20e+01, 3.31e+01\n",
      "S KL: 2.50e+07, 2.73e+07, 2.98e+07, 2.90e+07, 3.00e+07\n",
      "----------------------------------------\n",
      "LR: 0.1\n",
      "Elapsed time (secs): 0.11953997611999512\n",
      "----------------------------------------\n",
      "CPU cur memory used (GB): 2.70e-01\n",
      "\n",
      "=========== EPOCH 100 COMPLETE ===========\n",
      "Obj: 3.78e+06\n",
      "----------------------------------------\n",
      "NELL: 5.92e+05, 7.21e+05, 8.69e+05, 8.06e+05, 7.67e+05\n",
      "Latent KL: 5.04e+03, 5.68e+03, 6.87e+03, 6.39e+03, 5.33e+03\n",
      "LM KL: 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00\n",
      "Mn KL: 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00\n",
      "Psi KL: 9.45e+01, 6.62e+01, 1.06e+02, 6.98e+01, 9.27e+01\n",
      "S KL: 4.61e-02, 4.83e-02, 5.55e-02, 4.51e-02, 5.90e-02\n",
      "----------------------------------------\n",
      "LR: 0.010000000000000002\n",
      "Elapsed time (secs): 11.368337869644165\n",
      "----------------------------------------\n",
      "CPU cur memory used (GB): 2.78e-01\n",
      "\n",
      "=========== EPOCH 200 COMPLETE ===========\n",
      "Obj: 3.78e+06\n",
      "----------------------------------------\n",
      "NELL: 5.90e+05, 7.23e+05, 8.68e+05, 8.03e+05, 7.66e+05\n",
      "Latent KL: 5.32e+03, 5.80e+03, 6.72e+03, 6.34e+03, 5.62e+03\n",
      "LM KL: 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00\n",
      "Mn KL: 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00\n",
      "Psi KL: 7.64e+01, 5.57e+01, 9.25e+01, 6.58e+01, 7.78e+01\n",
      "S KL: 3.14e-03, 1.16e-02, 1.00e-02, 1.07e-02, 6.62e-03\n",
      "----------------------------------------\n",
      "LR: 0.010000000000000002\n",
      "Elapsed time (secs): 22.71057367324829\n",
      "----------------------------------------\n",
      "CPU cur memory used (GB): 2.81e-01\n",
      "\n",
      "=========== EPOCH 300 COMPLETE ===========\n",
      "Obj: 3.78e+06\n",
      "----------------------------------------\n",
      "NELL: 5.92e+05, 7.21e+05, 8.70e+05, 8.02e+05, 7.65e+05\n",
      "Latent KL: 5.42e+03, 6.09e+03, 6.73e+03, 6.15e+03, 5.64e+03\n",
      "LM KL: 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00\n",
      "Mn KL: 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00\n",
      "Psi KL: 7.34e+01, 5.00e+01, 8.98e+01, 6.05e+01, 7.48e+01\n",
      "S KL: 4.03e-03, 9.06e-03, 9.69e-03, 1.02e-02, 6.72e-03\n",
      "----------------------------------------\n",
      "LR: 0.010000000000000002\n",
      "Elapsed time (secs): 33.994669675827026\n",
      "----------------------------------------\n",
      "CPU cur memory used (GB): 2.82e-01\n"
     ]
    }
   ],
   "source": [
    "sp_fitter.distribute(distribute_data=True, devices=devices)\n",
    "sp_logs = [sp_fitter.fit(1000, milestones=[100], update_int=100, init_lr=.1) for fit_r in range(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-stake",
   "metadata": {},
   "source": [
    "## Examine logs of sp fitting performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "for log in sp_logs:\n",
    "    sp_fitter.plot_log(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-sellers",
   "metadata": {},
   "source": [
    "## Look at sp model fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_mdl = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_lm = sp_vi_collections[exam_mdl].posteriors.lm_post(ind_props[exam_mdl]).detach().squeeze()\n",
    "fit_mn = sp_vi_collections[exam_mdl].posteriors.mn_post(ind_props[exam_mdl]).detach().squeeze()\n",
    "fit_psi = sp_vi_collections[exam_mdl].posteriors.psi_post.mode(ind_props[exam_mdl]).detach().squeeze()\n",
    "fit_s = sp_vi_collections[exam_mdl].posteriors.s_post(ind_props[exam_mdl]).detach().squeeze()\n",
    "\n",
    "cmp_mdl = GNLDRMdl(n_latent_vars=n_latent_vars, \n",
    "                   m=sp_m_fit, lm=fit_lm, mn=fit_mn, psi=fit_psi, s=fit_s)\n",
    "true_mdl = ind_true_mdls[exam_mdl]\n",
    "\n",
    "plt.figure()\n",
    "true_mdl.compare_models(true_mdl, cmp_mdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-louisiana",
   "metadata": {},
   "source": [
    "## Setup everything for fitting models with individual posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_m_fit = copy.deepcopy(sp_m_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_priors = copy.deepcopy(sp_priors)\n",
    "\n",
    "ip_posteriors = generate_basic_posteriors(n_obs_vars=ind_n_vars, n_smps=ind_n_smps, n_latent_vars=n_latent_vars, \n",
    "                                          n_intermediate_latent_vars=n_intermediate_latent_vars,\n",
    "                                          s_opts={'mn_mn': s_mn, 'mn_std': .00000001, 'std_iv': .01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s_i, posteriors in enumerate(ip_posteriors):\n",
    "    \n",
    "    # Initialize the poseteriors for the mean vectors\n",
    "    with torch.no_grad():\n",
    "        mn_prior_mn = sp_priors.mn_prior(ind_props[s_i]).squeeze()\n",
    "        mn_prior_std = sp_priors.mn_prior.std_f(ind_props[s_i]).squeeze()\n",
    "    \n",
    "        posteriors.mn_post.dists[0].mn_f.f.vl.data = copy.deepcopy(mn_prior_mn)\n",
    "        posteriors.mn_post.dists[0].std_f.f.set_value(copy.deepcopy(mn_prior_std.numpy()))\n",
    "        \n",
    "    # Initialize the posteriors for the loading matrices\n",
    "    with torch.no_grad():\n",
    "          \n",
    "        for d_i in range(n_latent_vars):\n",
    "            cur_mn = sp_priors.lm_prior.dists[d_i](ind_props[s_i]).squeeze()\n",
    "            cur_std = sp_priors.lm_prior.dists[d_i].std_f(ind_props[s_i]).squeeze().numpy()\n",
    "            \n",
    "            posteriors.lm_post.dists[d_i].mn_f.f.vl.data = copy.deepcopy(cur_mn)\n",
    "            posteriors.lm_post.dists[d_i].std_f.f.set_value(copy.deepcopy(cur_std))\n",
    "        \n",
    "    # Initialize the posteriors for the private variances\n",
    "    posteriors.psi_post = copy.deepcopy(sp_posteriors[s_i].psi_post)\n",
    "    \n",
    "    # Initialize the posteriors for the scales\n",
    "    #posteriors.s_post = copy.deepcopy(sp_posteriors[s_i].s_post)\n",
    "    \n",
    "    # Initialize the posteriors for the latents\n",
    "    with torch.no_grad():\n",
    "        posteriors.latent_post = copy.deepcopy(sp_posteriors[s_i].latent_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_fit_mdls = [GNLDRMdl(n_latent_vars=n_latent_vars, m=ip_m_fit, lm=None, mn=None, psi=None, s=None) \n",
    "               for i in range(n_individuals)]\n",
    "                    \n",
    "                    \n",
    "                   \n",
    "ip_vi_collections = [VICollection(data=ind_data[s_i][1], \n",
    "                                  props=ind_props[s_i],\n",
    "                                  mdl = ip_fit_mdls[s_i],\n",
    "                                  posteriors = ip_posteriors[s_i]) for s_i in range(n_individuals)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-theorem",
   "metadata": {},
   "source": [
    "## Fit ip model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_fitter = Fitter(vi_collections=ip_vi_collections, priors=ip_priors, devices=devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_fitter.distribute(distribute_data=True, devices=devices)\n",
    "ip_logs = [ip_fitter.fit(200, milestones=[100, 500], update_int=100, init_lr=.1) for fit_r in range(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-influence",
   "metadata": {},
   "source": [
    "## Look at aligned ip model fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_mdl = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_lm = ip_vi_collections[exam_mdl].posteriors.lm_post(ind_props[exam_mdl]).detach().squeeze()\n",
    "fit_mn = ip_vi_collections[exam_mdl].posteriors.mn_post(ind_props[exam_mdl]).detach().squeeze()\n",
    "fit_psi = ip_vi_collections[exam_mdl].posteriors.psi_post.mode(ind_props[exam_mdl]).detach().squeeze()\n",
    "fit_s = ip_vi_collections[exam_mdl].posteriors.s_post(ind_props[exam_mdl]).detach().squeeze()\n",
    "\n",
    "cmp_mdl = GNLDRMdl(n_latent_vars=n_latent_vars, m=Identity(), lm=fit_lm, mn=fit_mn, psi=fit_psi, s=fit_s)\n",
    "\n",
    "plt.figure()\n",
    "true_mdl.compare_models(ind_true_mdls[exam_mdl], cmp_mdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-secretariat",
   "metadata": {},
   "source": [
    "## Look at true and estimated intermediate latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_z_true = m_true(ind_data[exam_mdl][0]).detach().numpy()\n",
    "intermediate_z_fit = ip_m_fit(ip_posteriors[exam_mdl].latent_post.mns).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_mn, aligned_lm, w, aligned_intermediate_z = align_intermediate_spaces(lm0=ind_true_mdls[exam_mdl].lm.detach().numpy(), \n",
    "                          mn0=ind_true_mdls[exam_mdl].mn.detach().numpy(),\n",
    "                          s0=ind_true_mdls[exam_mdl].s.detach().numpy(),\n",
    "                          lm1=fit_lm.detach().numpy(), \n",
    "                          mn1=fit_mn.detach().numpy(),\n",
    "                          s1=fit_s.detach().numpy(), \n",
    "                          int_z0=intermediate_z_true, \n",
    "                          int_z1=intermediate_z_fit, \n",
    "                          align_by_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(3):\n",
    "    plt.subplot(3,1,i+1)\n",
    "    plt.plot(intermediate_z_true[:, i], aligned_intermediate_z[:, i], 'r.')\n",
    "    plt.plot([-4, 4], [-4, 4], 'k-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-adoption",
   "metadata": {},
   "source": [
    "## Look at points from all individuals in the intermediate space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "a_true = plt.subplot(1,2,1, projection='3d')\n",
    "a_fit = plt.subplot(1,2,2, projection='3d')\n",
    "\n",
    "for i in range(n_individuals):\n",
    "    \n",
    "    intermediate_z_true = m_true(ind_data[i][0]).detach().numpy()\n",
    "    intermediate_z_fit = ip_m_fit(ip_posteriors[i].latent_post.mns).detach().numpy()\n",
    "    \n",
    "    clrs = assign_colors_to_pts(ind_data[i][0], lims=np.asarray([[-2, 2], [-2, 2]]))\n",
    "    \n",
    "    fit_lm = ip_vi_collections[i].posteriors.lm_post(ind_props[i]).detach().squeeze()\n",
    "    fit_mn = ip_vi_collections[i].posteriors.mn_post(ind_props[i]).detach().squeeze()\n",
    "    fit_psi = ip_vi_collections[i].posteriors.psi_post.mode(ind_props[i]).detach().squeeze()\n",
    "    fit_s = ip_vi_collections[i].posteriors.s_post(ind_props[i]).detach().squeeze()\n",
    "    \n",
    "    _, _, w, aligned_intermediate_z = align_intermediate_spaces(lm0=ind_true_mdls[i].lm.detach().numpy(), \n",
    "                                                                mn0=ind_true_mdls[i].mn.detach().numpy(),\n",
    "                                                                s0=ind_true_mdls[i].s.detach().numpy(),\n",
    "                                                                lm1=fit_lm.detach().numpy(), \n",
    "                                                                mn1=fit_mn.detach().numpy(),\n",
    "                                                                s1=fit_s.detach().numpy(), \n",
    "                                                                int_z0=intermediate_z_true, \n",
    "                                                                int_z1=intermediate_z_fit, \n",
    "                                                                align_by_params=True)\n",
    "\n",
    "    plot_three_dim_pts(intermediate_z_true, clrs=clrs, a=a_true)\n",
    "    plot_three_dim_pts(aligned_intermediate_z, clrs=clrs, a=a_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-audience",
   "metadata": {},
   "source": [
    "## View latents in low-d space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "a_true = plt.subplot(1, 2, 1)\n",
    "a_fit = plt.subplot(1, 2, 2)\n",
    "\n",
    "for i in range(n_individuals):\n",
    "    \n",
    "    orig_z = ind_data[i][0].numpy()\n",
    "    fit_z = ip_posteriors[i].latent_post.mns.detach().numpy()\n",
    "    \n",
    "    clrs = assign_colors_to_pts(orig_z, lims=np.asarray([[-2, 2], [-2, 2]]))\n",
    "    \n",
    "    a_true.scatter(orig_z[:,0], orig_z[:,1], c=clrs)\n",
    "    \n",
    "    \n",
    "    a_fit.scatter(fit_z[:,0], fit_z[:,1], c=clrs)\n",
    "    \n",
    "a_true.axis('equal')\n",
    "a_fit.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-confidentiality",
   "metadata": {},
   "source": [
    "## Examine true and fit distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_mean_and_lm_dists(lm_0_prior=true_priors.lm_prior, mn_0_prior = true_priors.mn_prior,\n",
    "                          s_0_prior = true_priors.s_prior, lm_1_prior = ip_priors.lm_prior,\n",
    "                          mn_1_prior = ip_priors.mn_prior, s_1_prior = ip_priors.s_prior, \n",
    "                          dim_0_range=[0, 1], dim_1_range=[0, 1], n_pts_per_dim=[20, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-occasions",
   "metadata": {},
   "source": [
    "### Visualize parameters of the true prior distribution over private variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,3))\n",
    "plot_torch_dist(mn_f=true_priors.psi_prior.forward, std_f=true_priors.psi_prior.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,3))\n",
    "plot_torch_dist(mn_f=ip_priors.psi_prior.forward, std_f=ip_priors.psi_prior.std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-concentration",
   "metadata": {},
   "source": [
    "## Compare means conditioned on latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_mns = ind_true_mdls[exam_mdl].cond_mean(ind_data[exam_mdl][0]).detach().numpy()\n",
    "fit_mns = ip_vi_collections[exam_mdl].mdl.cond_mean(z=ip_posteriors[exam_mdl].latent_post.mns, \n",
    "                                                    lm=fit_lm, \n",
    "                                                    mn=fit_mn, \n",
    "                                                    s=fit_s, \n",
    "                                                    psi=fit_psi).detach().numpy()\n",
    "\n",
    "plt.figure()\n",
    "cmp_n_mats([true_mns, fit_mns, fit_mns-true_mns], show_colorbars=True)\n",
    "#cmp_n_mats([ind_data[exam_mdl][1].numpy(), fit_mns, fit_mns-ind_data[exam_mdl][1].numpy()], show_colorbars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-malawi",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
