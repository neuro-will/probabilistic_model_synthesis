{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segments data for for fitting models to different data across fish. \n",
    "\n",
    "\n",
    "The way we segment data is very basic.  The user first specified a set of groups (e.g., omr left) and then for each fish we break the data for each group into a given set of chunks of a fixed size (e.g., 5 time poitns).  We order these chunks according to the power of swimming in each chunk and then assign each chunk to it's own segment (so in this special case, segments and chunks are the same thing).  By ordering the chunks by swim power, we can then try to balance swim power when breaking data up into train/validation sets in the notebook form_folds_for_across_cond_analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from ahrens_wbo.annotations import label_subperiods\n",
    "from ahrens_wbo.data_processing import SegmentTable\n",
    "from ahrens_wbo.data_processing import segment_dataset_with_constant_segment_sizes\n",
    "from ahrens_wbo.raw_data_processing import load_processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = dict()\n",
    "ps['data_dir'] = r'/groups/bishop/bishoplab/projects/ahrens_wbo/data'\n",
    "\n",
    "# Specify subjects\n",
    "ps['subjects'] =  [8, 9, 10, 11]\n",
    "\n",
    "# Specify size of chunks data up into - we form sets out of chunks\n",
    "ps['chunk_size'] = 5\n",
    "\n",
    "# Specify which behavioral channels we will use for calculating values to associate with each sample point\n",
    "ps['value_chs'] = [3, 4]\n",
    "\n",
    "# Specify how we will group the data\n",
    "ps['groups'] = OrderedDict([('omr_l_ns', [{'period': 'omr_left', 'shock': False}]),\n",
    "                            ('omr_r_ns', [{'period': 'omr_right', 'shock': False}]),\n",
    "                            ('omr_f_ns', [{'period': 'omr_forward', 'shock': False}])])                                                                                                      \n",
    "# Specify value function\n",
    "ps['value_fnc'] = 'max'\n",
    "    \n",
    "# Specify where we should save the segment information\n",
    "ps['save_folder'] = r'/groups/bishop/bishoplab/projects/probabilistic_model_synthesis/results/real_data/'\n",
    "ps['save_name'] = r'omr_l_r_f_ns_across_cond_segments_8_9_10_11.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of labels for each dataset and swim values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading subject 8\n",
      "Done loading subject 9\n",
      "Done loading subject 10\n",
      "Done loading subject 11\n"
     ]
    }
   ],
   "source": [
    "n_subjects = len(ps['subjects'])\n",
    "labels = dict()\n",
    "values = dict()\n",
    "for subject_id in ps['subjects']:\n",
    "    dataset = load_processed_data(Path(ps['data_dir']) / ('subject_' + str(subject_id)), subject_id)\n",
    "    labels[subject_id] = label_subperiods(dataset.ts_data['stim']['vls'][:])\n",
    "    values[subject_id] = dataset.ts_data['behavior']['vls'][:, ps['value_chs']]\n",
    "    print('Done loading subject ' + str(subject_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ps['value_fnc'] == 'mean':\n",
    "    value_fnc = lambda x: np.mean(x)\n",
    "elif ps['value_fnc'] == 'max':\n",
    "    value_fnc = lambda x: np.max(x)\n",
    "else:\n",
    "    raise(ValueError('value_fcn is not recogonized'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_tables = OrderedDict()\n",
    "for s_n in ps['subjects']:\n",
    "    subj_values = np.mean(values[s_n], axis=1)\n",
    "    segment_tables[s_n] = segment_dataset_with_constant_segment_sizes(period_lbls=labels[s_n], \n",
    "                                                                      groups=ps['groups'], \n",
    "                                                                      chunk_size=ps['chunk_size'],\n",
    "                                                                      n_segment_chunks=1, \n",
    "                                                                      vls=subj_values, vl_fnc=value_fnc, \n",
    "                                                                      random_vl_assignment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the segment tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s_n in ps['subjects']:\n",
    "    segment_tables[s_n] = segment_tables[s_n].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path(Path(ps['save_folder']) / ps['save_name'])\n",
    "rs = {'ps': ps, 'segment_tables': segment_tables}\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(rs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment tables saved to: /groups/bishop/bishoplab/projects/probabilistic_model_synthesis/results/real_data/omr_l_r_f_ns_across_cond_segments_8_9_10_11.pkl\n"
     ]
    }
   ],
   "source": [
    "print('Segment tables saved to: ' + str(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'slice': slice(1030, 1060, None), 'shock': False},\n",
       " {'slice': slice(1180, 1210, None), 'shock': False},\n",
       " {'slice': slice(1330, 1360, None), 'shock': False},\n",
       " {'slice': slice(1480, 1510, None), 'shock': False},\n",
       " {'slice': slice(1630, 1660, None), 'shock': False},\n",
       " {'slice': slice(1780, 1810, None), 'shock': False},\n",
       " {'slice': slice(1930, 1960, None), 'shock': False},\n",
       " {'slice': slice(2080, 2110, None), 'shock': False},\n",
       " {'slice': slice(2230, 2260, None), 'shock': False},\n",
       " {'slice': slice(3580, 3610, None), 'shock': True},\n",
       " {'slice': slice(3730, 3760, None), 'shock': True},\n",
       " {'slice': slice(3880, 3910, None), 'shock': True},\n",
       " {'slice': slice(4030, 4060, None), 'shock': True},\n",
       " {'slice': slice(4180, 4210, None), 'shock': True},\n",
       " {'slice': slice(4330, 4360, None), 'shock': True},\n",
       " {'slice': slice(4480, 4510, None), 'shock': True},\n",
       " {'slice': slice(4630, 4660, None), 'shock': True},\n",
       " {'slice': slice(4780, 4810, None), 'shock': True},\n",
       " {'slice': slice(6250, 6280, None), 'shock': False},\n",
       " {'slice': slice(6400, 6430, None), 'shock': False},\n",
       " {'slice': slice(6550, 6580, None), 'shock': False},\n",
       " {'slice': slice(6700, 6730, None), 'shock': False},\n",
       " {'slice': slice(6850, 6880, None), 'shock': False},\n",
       " {'slice': slice(7000, 7030, None), 'shock': False},\n",
       " {'slice': slice(7150, 7180, None), 'shock': False},\n",
       " {'slice': slice(7300, 7330, None), 'shock': False},\n",
       " {'slice': slice(7450, 7480, None), 'shock': False}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[8]['omr_right'][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[slice(600, 620, 1),\n",
       " slice(720, 740, 1),\n",
       " slice(840, 860, 1),\n",
       " slice(960, 980, 1),\n",
       " slice(1080, 1100, 1),\n",
       " slice(1200, 1220, 1)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_tables[10].find_all({'omr_l_ns': segment_tables[10].segments})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_tables[10].grp_segment_slices[0][0] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[slice(685, 690, None)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_tables[10].grp_segment_slices[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
