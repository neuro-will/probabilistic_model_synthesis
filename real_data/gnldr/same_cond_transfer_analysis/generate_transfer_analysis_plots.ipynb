{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fed5d71",
   "metadata": {},
   "source": [
    "A notebook for generating the final results for a fully cross-validated transfer analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8aa3bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3af6c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from janelia_core.utils.file_system import get_immediate_subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6316b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ebc29c",
   "metadata": {},
   "source": [
    "## Parameters go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "450764d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of of base_folders with the results of different analyses.  A single analysis consists of \n",
    "# runing the full cross-validated results with multiple amounts of training data for models fit\n",
    "# both individually and combined, with a *single* set of parameters.  In this convention, we could \n",
    "# run different analyses using different numbers of hypercubes in the prior, for example, and then compare results. \n",
    "\n",
    "base_folders = [r'/groups/bishop/bishoplab/projects/probabilistic_model_synthesis/results/real_data/gnldr/same_cond_transfer_analysis/v2']\n",
    "\n",
    "# The names of files holding post-processed results for each type of analysis\n",
    "results_files = ['pp_test_results.pt']\n",
    "\n",
    "# Subjects we want to evaluate performance on\n",
    "eval_subjs = [8]#, 9, 10, 11]\n",
    "\n",
    "subj_clrs = np.asarray([[1.0, 0.0, 0.0],\n",
    "                        [0.0, 1.0, 0.0], \n",
    "                        [0.0, 0.0, 1.0], \n",
    "                        [1.0, 1.0, 0.0]])\n",
    "\n",
    "# Training quantities we want to evaluate performance on\n",
    "tq_strings = ['fold_str_base_14_tgt_1']#, \n",
    "              #'fold_str_base_14_tgt_2',\n",
    "              #'fold_str_base_14_tgt_4',\n",
    "              #'fold_str_base_14_tgt_8',\n",
    "              #'fold_str_base_14_tgt_14']\n",
    "\n",
    "tq_fracs = np.asarray([1.0/14])#, \n",
    "                      # 2.0/14, \n",
    "                      # 4.0/14,\n",
    "                      # 8.0/14,\n",
    "                      # 14.0/14.0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beaba41",
   "metadata": {},
   "source": [
    "## Define helper functions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "534c3cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analysis_results(base_folder, results_file, fit_type: str = 'ip', data_type: str = 'test'):\n",
    "    training_quantity_folders = get_immediate_subfolders(base_folder)\n",
    "    training_quantity_folders = tq_strings\n",
    "    tq_rs = dict()\n",
    "    for tq_folder in training_quantity_folders:\n",
    "        #print('TQ folder: ' + tq_folder)\n",
    "        tq_folder_path = pathlib.Path(base_folder) / tq_folder\n",
    "        fold_folders = get_immediate_subfolders(tq_folder_path)\n",
    "        n_folds = len(fold_folders)\n",
    "        fold_rs = dict()\n",
    "        for fold_folder in fold_folders:\n",
    "            cur_fold = int(re.match('.*_(\\d*)', fold_folder)[1])\n",
    "            #print('Fold: ' + str(cur_fold))\n",
    "            fold_folder_path = pathlib.Path(tq_folder_path) / fold_folder\n",
    "            subj_folders = get_immediate_subfolders(fold_folder_path)\n",
    "            n_subjs = len(subj_folders)\n",
    "            subj_rs = dict()\n",
    "            for subj_folder in subj_folders:\n",
    "                #print('Subject folder: ' + subj_folder)\n",
    "                subj_folder_path = pathlib.Path(fold_folder_path) / subj_folder\n",
    "                type_folders = get_immediate_subfolders(subj_folder_path)\n",
    "                eval_subj = int(re.match('.*_(\\d*)', subj_folder)[1])\n",
    "                #print('Eval Subject: ' + str(eval_subj))\n",
    "                type_rs = dict()\n",
    "                for type_folder in type_folders:\n",
    "                    #print('Type Folder: ' + str(type_folder))\n",
    "                    cur_type = type_folder\n",
    "                    type_folder_path = pathlib.Path(subj_folder_path) / type_folder\n",
    "                    results_file_path = type_folder_path / results_file\n",
    "                    #print('Results file path: ' + str(results_file_path))\n",
    "                    c_rs = torch.load(results_file_path)\n",
    "                    elbo = c_rs[fit_type]['elbo_vls'][eval_subj][data_type]['elbo'].item()\n",
    "                    type_rs[cur_type] = elbo\n",
    "                subj_rs[eval_subj] = type_rs\n",
    "            fold_rs[cur_fold] = subj_rs\n",
    "        tq_rs[tq_folder] = fold_rs\n",
    "    return tq_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeab683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subj_rs(rs, subj, fit_type: str = 'ind'):\n",
    "    \"\"\" Gets average performance for a single subject, for each for fold, for a single fit type \n",
    "        for a single training quantity. \"\"\"\n",
    "    n_folds = len(rs)\n",
    "    folds = np.sort(np.asarray(list(rs.keys())))\n",
    "    \n",
    "    fold_rs = np.zeros(n_folds)\n",
    "    for f_i, f_n in enumerate(folds):\n",
    "        fold_rs[f_i] = np.mean(rs[f_n][subj][fit_type])\n",
    "    return fold_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "128a34aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_fit_type_rs_for_fixed_training_quantity(rs, subjs, fit_type: str = 'ind'):\n",
    "    \"\"\" Gets average and standard error of performance across folds for multiple subjects for a single fit type\n",
    "        and for a single training quantity.\"\"\"\n",
    "    n_subjs = len(subjs)\n",
    "    mn_rs = np.zeros(n_subjs)\n",
    "    std_er_rs = np.zeros(n_subjs)\n",
    "    for s_i, subj in enumerate(subjs):\n",
    "        fold_rs = get_subj_rs(rs, subj=subj, fit_type=fit_type)\n",
    "        mn_rs[s_i] = np.mean(fold_rs)\n",
    "        std_er_rs[s_i] = np.std(fold_rs)/np.sqrt(len(fold_rs))\n",
    "    return [mn_rs, std_er_rs]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ff1ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fit_type_rs(rs, train_quantity_keys, subjs, fit_type: str = 'ind'):\n",
    "    n_train_quantity_keys = len(train_quantity_keys)\n",
    "    n_subjs = len(subjs)\n",
    "    mn_rs = np.zeros([n_train_quantity_keys, n_subjs])\n",
    "    std_er_rs = np.zeros([n_train_quantity_keys, n_subjs])\n",
    "    for tq_i, tq_key in enumerate(train_quantity_keys):\n",
    "        mn_rs[tq_i, :],  std_er_rs[tq_i, :] = get_avg_fit_type_rs_for_fixed_training_quantity(rs[tq_key], subjs, fit_type)\n",
    "    return mn_rs, std_er_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "244387e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_rs = get_analysis_results(base_folders[0], results_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59e21534",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_rs = get_fit_type_rs(c_rs, tq_strings, subjs=eval_subjs, fit_type='comb')\n",
    "ind_rs = get_fit_type_rs(c_rs, tq_strings, subjs=eval_subjs, fit_type='ind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "143f2133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-65695672.]]), array([[0.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1f2f7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-67481216.]]), array([[0.]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b3338",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_avg = np.mean(comb_rs[0], axis=1)\n",
    "ind_avg = np.mean(ind_rs[0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fe09ca",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a313c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = plt.subplot(1,1,1)\n",
    "for s_i, subj in enumerate(eval_subjs):\n",
    "    plt.plot(tq_fracs, comb_rs[0][:, s_i], '-', color=subj_clrs[s_i])\n",
    "plt.legend(eval_subjs)\n",
    "plt.xlabel('Training Percentage')\n",
    "plt.ylabel('ELBO')\n",
    "\n",
    "for s_i, subj in enumerate(eval_subjs):\n",
    "    plt.plot(tq_fracs, ind_rs[0][:, s_i], '--', color=subj_clrs[s_i])\n",
    "#ax.set_ylim([0, 1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tq_fracs, comb_avg, 'k-')\n",
    "plt.plot(tq_fracs, ind_avg, 'k--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f03884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
