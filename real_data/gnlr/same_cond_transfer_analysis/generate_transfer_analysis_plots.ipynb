{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0b43242",
   "metadata": {},
   "source": [
    "A notebook for generating the final results for a fully cross-validated transfer analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94123833",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c76f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/bishop/bishoplab/projects/janelia_core/janelia_core/visualization/volume_visualization.py:22: UserWarning: Unable to import moviepy.  Minor functionality will not be available.\n",
      "  warnings.warn('Unable to import moviepy.  Minor functionality will not be available.')\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import glob\n",
    "import os\n",
    "import os.path\n",
    "import pathlib\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch\n",
    "\n",
    "from ahrens_wbo.data_processing import label_periods\n",
    "from ahrens_wbo.data_processing import load_and_preprocess_data\n",
    "from ahrens_wbo.visualization import plot_segmented_signal\n",
    "\n",
    "from probabilistic_model_synthesis.gaussian_nonlinear_regression import PriorCollection\n",
    "from probabilistic_model_synthesis.gaussian_nonlinear_regression import VICollection\n",
    "\n",
    "from janelia_core.stats.regression import r_squared\n",
    "from janelia_core.utils.file_system import get_immediate_subfolders\n",
    "from janelia_core.visualization.custom_color_maps import make_purple_green_c_map\n",
    "from janelia_core.visualization.image_generation import generate_dot_image_3d\n",
    "from janelia_core.visualization.volume_visualization import signed_max_proj\n",
    "from janelia_core.visualization.volume_visualization import visualize_projs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7abf8d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d84b68",
   "metadata": {},
   "source": [
    "## Parameters go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b821cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of of base_folders with the results of different analyses.  A single analysis consists of \n",
    "# runing the full cross-validated results with multiple amounts of training data for models fit\n",
    "# both individually and combined, with a *single* set of parameters.  In this convention, we could \n",
    "# run different analyses using different numbers of hypercubes in the prior, for example, and then compare results. \n",
    "\n",
    "base_folders = [r'/groups/bishop/bishoplab/projects/probabilistic_model_synthesis/results/real_data/gnlr/same_cond_transfer_analysis/v18']\n",
    "\n",
    "# The names of files holding post-processed results for each type of analysis\n",
    "results_files = ['pp_test_results.pkl']\n",
    "\n",
    "# Subjects we want to evaluate performance on\n",
    "eval_subjs = [8, 10, 11]\n",
    "\n",
    "subj_clrs = np.asarray([[1.0, 0.0, 0.0],\n",
    "                        [0.0, 1.0, 0.0], \n",
    "                        [0.0, 0.0, 1.0]])\n",
    "\n",
    "# Training quantities we want to evaluate performance on\n",
    "tq_strings = ['fold_str_base_14_tgt_1', \n",
    "              'fold_str_base_14_tgt_2',\n",
    "              'fold_str_base_14_tgt_4',\n",
    "              'fold_str_base_14_tgt_8',\n",
    "              'fold_str_base_14_tgt_14']\n",
    "tq_fracs = np.asarray([1.0/14, \n",
    "                       2.0/14, \n",
    "                       4.0/14,\n",
    "                       8.0/14,\n",
    "                       14.0/14.0])\n",
    "\n",
    "# Location of folder holding the raw dataset to plot example data from \n",
    "raw_folder = r'/groups/bishop/bishoplab/projects/ahrens_wbo/data'\n",
    "\n",
    "# Location to anatomical stack\n",
    "anat_file = r'/groups/bishop/bishoplab/projects/ahrens_wbo/data/ReferenceBrain.mat'\n",
    "\n",
    "# Location to example results folder\n",
    "ex_results_folder= r'/groups/bishop/bishoplab/projects/probabilistic_model_synthesis/results/real_data/gnlr/same_cond_transfer_analysis/v18/fold_str_base_14_tgt_14/fold_0/subj_10/comb/'\n",
    "\n",
    "# Subject we use as an example when plotting data and posteriors\n",
    "ex_subject = 10\n",
    "\n",
    "# Folder to save results in \n",
    "save_folder = r'/groups/bishop/bishoplab/projects/probabilistic_model_synthesis/results/real_data/gnlr/same_cond_transfer_analysis/v18'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aa808c",
   "metadata": {},
   "source": [
    "## Define helper functions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e6695dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(truth, est):\n",
    "    return np.sqrt(np.mean((truth - est)**2, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07c2e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(truth, est):\n",
    "    n_vars = truth.shape[1]\n",
    "    corr_coefs = np.zeros(n_vars)\n",
    "    for v_i in range(n_vars):\n",
    "        corr_coefs[v_i] = np.corrcoef(truth[:, v_i], est[:, v_i], rowvar=False)[0,1]\n",
    "    return corr_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e3eca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analysis_results(base_folder, results_file, fit_type: str = 'ip', data_type: str = 'test'):\n",
    "    training_quantity_folders = get_immediate_subfolders(base_folder)\n",
    "    tq_rs = dict()\n",
    "    for tq_folder in training_quantity_folders:\n",
    "        tq_folder_path = pathlib.Path(base_folder) / tq_folder\n",
    "        fold_folders = get_immediate_subfolders(tq_folder_path)\n",
    "        n_folds = len(fold_folders)\n",
    "        fold_rs = dict()\n",
    "        for fold_folder in fold_folders:\n",
    "            cur_fold = int(re.match('.*_(\\d*)', fold_folder)[1])\n",
    "            fold_folder_path = pathlib.Path(tq_folder_path) / fold_folder\n",
    "            subj_folders = get_immediate_subfolders(fold_folder_path)\n",
    "            n_subjs = len(subj_folders)\n",
    "            subj_rs = dict()\n",
    "            for subj_folder in subj_folders:\n",
    "                subj_folder_path = pathlib.Path(fold_folder_path) / subj_folder\n",
    "                type_folders = get_immediate_subfolders(subj_folder_path)\n",
    "                eval_subj = int(re.match('.*_(\\d*)', subj_folder)[1])\n",
    "                type_rs = dict()\n",
    "                for type_folder in type_folders:\n",
    "                    cur_type = type_folder\n",
    "                    type_folder_path = pathlib.Path(subj_folder_path) / type_folder\n",
    "                    results_file_path = type_folder_path / results_file\n",
    "                    with open(results_file_path, 'rb') as f: \n",
    "                        rs = pickle.load(f)\n",
    "                        r_sq = r_squared(rs[fit_type]['preds'][eval_subj][data_type]['y'], \n",
    "                                         rs[fit_type]['preds'][eval_subj][data_type]['y_hat'])\n",
    "                        \n",
    "                        rmse_vls = rmse(rs[fit_type]['preds'][eval_subj][data_type]['y'], \n",
    "                                        rs[fit_type]['preds'][eval_subj][data_type]['y_hat'])\n",
    "                        \n",
    "                        corr_vls = corr(rs[fit_type]['preds'][eval_subj][data_type]['y'], \n",
    "                                        rs[fit_type]['preds'][eval_subj][data_type]['y_hat'])\n",
    "                        \n",
    "                        raw_vls = {'truth': rs[fit_type]['preds'][eval_subj][data_type]['y'], \n",
    "                                   'est': rs[fit_type]['preds'][eval_subj][data_type]['y_hat'], \n",
    "                                   't': rs[fit_type]['preds'][eval_subj][data_type]['t']}\n",
    "                        \n",
    "                        n_smps = len(rs[fit_type]['preds'][eval_subj][data_type]['t'])\n",
    "                        elbo = rs[fit_type]['elbos'][eval_subj][data_type]['elbo'].item()/n_smps\n",
    "                        \n",
    "                        type_rs[cur_type] = {'r_sq': r_sq, 'rmse': rmse_vls, 'corr': corr_vls, 'elbo': elbo, \n",
    "                                             'raw': raw_vls}\n",
    "                subj_rs[eval_subj] = type_rs\n",
    "            fold_rs[cur_fold] = subj_rs\n",
    "        tq_rs[tq_folder] = fold_rs\n",
    "    return tq_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "907de920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subj_rs(rs, subj, fit_type: str = 'ind', metric: str = 'rmse'):\n",
    "    \"\"\" Gets average performance for a single subject, for each for fold, for a single fit type \n",
    "        for a single training quantity. \"\"\"\n",
    "    n_folds = len(rs)\n",
    "    folds = np.sort(np.asarray(list(rs.keys())))\n",
    "    \n",
    "    fold_rs = np.zeros(n_folds)\n",
    "    for f_i, f_n in enumerate(folds):\n",
    "        fold_rs[f_i] = np.mean(rs[f_n][subj][fit_type][metric]) # This is the mean across channels\n",
    "    return fold_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3d65b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_fit_type_rs_for_fixed_training_quantity(rs, subjs, fit_type: str = 'ind', metric: str = 'rmse'):\n",
    "    \"\"\" Gets average and standard error of performance across folds for multiple subjects for a single fit type\n",
    "        and for a single training quantity.\"\"\"\n",
    "    n_subjs = len(subjs)\n",
    "    mn_rs = np.zeros(n_subjs)\n",
    "    std_er_rs = np.zeros(n_subjs)\n",
    "    for s_i, subj in enumerate(subjs):\n",
    "        fold_rs = get_subj_rs(rs, subj=subj, fit_type=fit_type, metric=metric)\n",
    "        mn_rs[s_i] = np.mean(fold_rs)\n",
    "        std_er_rs[s_i] = np.std(fold_rs)/np.sqrt(len(fold_rs))\n",
    "    return [mn_rs, std_er_rs]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeba56db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fit_type_rs(rs, train_quantity_keys, subjs, fit_type: str = 'ind', metric: str = 'rmse'):\n",
    "    n_train_quantity_keys = len(train_quantity_keys)\n",
    "    n_subjs = len(subjs)\n",
    "    mn_rs = np.zeros([n_train_quantity_keys, n_subjs])\n",
    "    std_er_rs = np.zeros([n_train_quantity_keys, n_subjs])\n",
    "    for tq_i, tq_key in enumerate(train_quantity_keys):\n",
    "        mn_rs[tq_i, :],  std_er_rs[tq_i, :] = get_avg_fit_type_rs_for_fixed_training_quantity(rs[tq_key], \n",
    "                                                                                              subjs, fit_type, \n",
    "                                                                                              metric)\n",
    "    return mn_rs, std_er_rs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d7e8bd",
   "metadata": {},
   "source": [
    "## Get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40cea154",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_rs = get_analysis_results(base_folders[0], results_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614cad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_rmse_rs = get_fit_type_rs(c_rs, tq_strings, subjs=eval_subjs, fit_type='comb', metric='rmse')\n",
    "ind_rmse_rs = get_fit_type_rs(c_rs, tq_strings, subjs=eval_subjs, fit_type='ind', metric='rmse')\n",
    "\n",
    "comb_corr_rs = get_fit_type_rs(c_rs, tq_strings, subjs=eval_subjs, fit_type='comb', metric='corr')\n",
    "ind_corr_rs = get_fit_type_rs(c_rs, tq_strings, subjs=eval_subjs, fit_type='ind', metric='corr')\n",
    "\n",
    "comb_r_sq_rs = get_fit_type_rs(c_rs, tq_strings, subjs=eval_subjs, fit_type='comb', metric='r_sq')\n",
    "ind_r_sq_rs = get_fit_type_rs(c_rs, tq_strings, subjs=eval_subjs, fit_type='ind', metric='r_sq')\n",
    "\n",
    "comb_elbo = get_fit_type_rs(c_rs, tq_strings, subjs=eval_subjs, fit_type='comb', metric='elbo')\n",
    "ind_elbo = get_fit_type_rs(c_rs, tq_strings, subjs=eval_subjs, fit_type='ind', metric='elbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b805662",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26303bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = [2, 2]\n",
    "\n",
    "plot_results = [(comb_rmse_rs, ind_rmse_rs), \n",
    "                (comb_corr_rs, ind_corr_rs), \n",
    "                (comb_r_sq_rs, ind_r_sq_rs), \n",
    "                (comb_elbo, ind_elbo)\n",
    "               ]\n",
    "\n",
    "plot_strs = ['RMSE', 'Corr', 'R Sq.', 'Norm_ELBO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd99ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "capsize = 2\n",
    "for plot_rs, plot_str in zip(plot_results, plot_strs):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    for s_i, subj in enumerate(eval_subjs):\n",
    "        #plt.plot(tq_fracs, plot_rs[0][0][:, s_i], '-', color=subj_clrs[s_i])\n",
    "        plt.errorbar(x=tq_fracs, y=plot_rs[0][0][:, s_i], yerr=plot_rs[0][1][:, s_i], fmt='-', color=subj_clrs[s_i],\n",
    "                     capsize=capsize)\n",
    "    plt.legend(eval_subjs)\n",
    "    \n",
    "    comb_mn = np.mean(plot_rs[0][0], axis=1)\n",
    "    comb_std_er = np.std(plot_rs[0][0], axis=1)/np.shape(plot_rs[0][0])[1]\n",
    "    #plt.plot(tq_fracs, comb_mn, 'k-')\n",
    "    plt.errorbar(x=tq_fracs, y=comb_mn, yerr=ind_std_er, fmt='k-', capsize=capsize)\n",
    "    \n",
    "                                   \n",
    "    for s_i, subj in enumerate(eval_subjs):\n",
    "        #plt.plot(tq_fracs, plot_rs[1][0][:, s_i], '--', color=subj_clrs[s_i])  \n",
    "        plt.errorbar(x=tq_fracs, y=plot_rs[1][0][:, s_i], yerr=plot_rs[1][1][:, s_i], fmt='--', color=subj_clrs[s_i],\n",
    "                     capsize=capsize)\n",
    "    \n",
    "    ind_mn = np.mean(plot_rs[1][0], axis=1)\n",
    "    ind_std_er = np.std(plot_rs[1][0], axis=1)/np.shape(plot_rs[1][0])[1]\n",
    "    #plt.plot(tq_fracs, ind_mn, 'k--')\n",
    "    plt.errorbar(x=tq_fracs, y=ind_mn, yerr=ind_std_er, fmt='k--', capsize=capsize)\n",
    "                                   \n",
    "    plt.xlabel('Training Percentage')\n",
    "    plt.ylabel(plot_str)\n",
    "    \n",
    "    \n",
    "    save_name = plot_str + '.eps'\n",
    "    save_path = pathlib.Path(save_folder) / save_name\n",
    "    fig.savefig(save_path, format='eps')\n",
    "                                \n",
    "                                \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07abeee",
   "metadata": {},
   "source": [
    "## Look at example predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a741d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_comb_preds = c_rs['fold_str_base_14_tgt_1'][1][ex_subject]['comb']['raw']\n",
    "ex_ind_preds = c_rs['fold_str_base_14_tgt_1'][1][ex_subject]['ind']['raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdf84d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[6,figsize[1]])\n",
    "\n",
    "plot_segmented_signal(tm_pts=ex_comb_preds['t'], sig=ex_comb_preds['truth'][:,0], ax=ax, color='gray', \n",
    "                      remove_tm_btw_chunks=True)\n",
    "plot_segmented_signal(tm_pts=ex_comb_preds['t'], sig=ex_comb_preds['est'][:,0], ax=ax, color='k',\n",
    "                      remove_tm_btw_chunks=True)\n",
    "\n",
    "plot_segmented_signal(tm_pts=ex_ind_preds['t'], sig=ex_ind_preds['est'][:,0], ax=ax, color='b',\n",
    "                      remove_tm_btw_chunks=True)\n",
    "\n",
    "save_name = 'ex_sigs' + '.eps'\n",
    "save_path = pathlib.Path(save_folder) / save_name\n",
    "fig.savefig(save_path, format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a14af6",
   "metadata": {},
   "source": [
    "## Plot some raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a079fa",
   "metadata": {},
   "source": [
    "#### Load raw results - we don't use these for the moment, other than allowing us to know what the preprocessing parameters are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e91d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_rs = torch.load(pathlib.Path(ex_results_folder) / 'test_results.pt')\n",
    "\n",
    "with open(pathlib.Path(ex_results_folder) / 'pp_test_results.pkl', 'rb') as f:\n",
    "    ex_pp_rs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ce803",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_data, subject_neuron_locs = load_and_preprocess_data(data_folder=raw_folder,\n",
    "                                                                 subjects=[ex_subject],\n",
    "                                                                 normalize_beh_vars=ex_rs['ps']['normalize_beh_vars'],\n",
    "                                                                 neural_gain=ex_rs['ps']['neural_gain'],\n",
    "                                                                 beh_gain=ex_rs['ps']['beh_gain'],\n",
    "                                                                 z_ratio=ex_rs['ps']['z_ratio'])\n",
    "\n",
    "subject_data = subject_data[ex_subject]\n",
    "subject_neuron_locs = subject_neuron_locs[ex_subject]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce3a599",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = subject_data.ts_data['stim']['ts']\n",
    "stim_vls = subject_data.ts_data['stim']['vls'][:]\n",
    "dff = subject_data.ts_data['dff']['vls'][:]\n",
    "beh = subject_data.ts_data['behavior']['vls'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c29e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = label_periods(stim_vls)\n",
    "ex_slice = periods['phototaxis'][0]['slice']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f690f5aa",
   "metadata": {},
   "source": [
    "#### Plot electrode signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b425082",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[4,1])\n",
    "ax.plot(ts[ex_slice], beh[ex_slice,0], 'k-')\n",
    "ax.plot(ts[ex_slice], beh[ex_slice,1]+100, 'k-')\n",
    "\n",
    "save_name = 'electrode_sigs' + '.eps'\n",
    "save_path = pathlib.Path(save_folder) / save_name\n",
    "fig.savefig(save_path, format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc6e933",
   "metadata": {},
   "source": [
    "#### Plot neural activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c75242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_neuron_inds = [5000, 1100, 15000, 20000, 25000, 30000, 40100, 70500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c80fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[4,2])\n",
    "for i, neuron_i in enumerate(ex_neuron_inds):\n",
    "    raw_dff = dff[ex_slice,neuron_i]\n",
    "    norm_dff = (raw_dff - np.min(raw_dff))/(np.max(raw_dff) - np.min(raw_dff))\n",
    "    ax.plot(ts[ex_slice], .8*norm_dff + i, 'k-')\n",
    "    \n",
    "save_name = 'dff' + '.eps'\n",
    "save_path = pathlib.Path(save_folder) / save_name\n",
    "fig.savefig(save_path, format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e813e2d0",
   "metadata": {},
   "source": [
    "## Visualize mean of modes under poseterior and MCPD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b830e2fb",
   "metadata": {},
   "source": [
    "#### Load and prepare the image of the raw volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f75a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_brain = scipy.io.loadmat(anat_file)\n",
    "ref_brain = ref_brain['anat_stack_norm']\n",
    "ref_brain = ref_brain/np.max(ref_brain)\n",
    "\n",
    "rb_horz = signed_max_proj(ref_brain,2)\n",
    "rb_sag = signed_max_proj(ref_brain,1)\n",
    "rb_cor = np.fliplr(signed_max_proj(ref_brain,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecb898e",
   "metadata": {},
   "source": [
    "#### Visualize posterior mode for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af311ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cp_ind = ex_pp_rs['ip']['early_stopping']['best_cp_ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40adc4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load check points\n",
    "cp_dir = pathlib.Path(ex_results_folder) / 'ip_cp'\n",
    "cp_files = glob.glob(str(cp_dir / 'cp_*.pt'))\n",
    "n_cps = len(cp_files)\n",
    "cp_rs = [None] * n_cps\n",
    "for cp_i, cp_file in enumerate(cp_files):\n",
    "    cp_rs[cp_i] = torch.load(cp_file)\n",
    "\n",
    "# Sort check points by epoch\n",
    "cp_epochs = np.asarray([cp['total_epoch'] for cp in cp_rs])\n",
    "cp_sort_order = np.argsort(cp_epochs)\n",
    "cp_epochs = cp_epochs[cp_sort_order]\n",
    "cp_rs = [cp_rs[i] for i in cp_sort_order]\n",
    "\n",
    "# Get beck check point\n",
    "best_cp = cp_rs[best_cp_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f717f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_ind = np.argwhere(np.asarray(ex_rs['subject_order']) == ex_subject)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eaaa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_w_post = best_cp['vi_collections'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52581e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cp_ind = ex_pp_rs['ip']['early_stopping']['best_cp_ind']\n",
    "ex_w_post = VICollection.from_checkpoint(best_cp['vi_collections'][4]).posteriors.w_post\n",
    "ex_prior = PriorCollection.from_checkpoint(best_cp['priors']).w_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f72bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_mode = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad146cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_mn = ex_w_post(subject_neuron_locs).detach().numpy()\n",
    "prior_mn = ex_prior(subject_neuron_locs).detach().numpy()\n",
    "mn_diff = post_mn - prior_mn\n",
    "\n",
    "dot_ctrs = copy.deepcopy(subject_neuron_locs.numpy())\n",
    "dot_ctrs[:,2] = dot_ctrs[:,2]/ex_rs['ps']['z_ratio']\n",
    "\n",
    "post_img = generate_dot_image_3d(image_shape=[990, 610, 138],\n",
    "                                         dot_ctrs=dot_ctrs,\n",
    "                                         dot_vls=post_mn[:, ex_mode],\n",
    "                                         ellipse_shape=[5,5,5])\n",
    "\n",
    "prior_img = generate_dot_image_3d(image_shape=[990, 610, 138],\n",
    "                                         dot_ctrs=dot_ctrs,\n",
    "                                         dot_vls=prior_mn[:, ex_mode],\n",
    "                                         ellipse_shape=[5,5,5])\n",
    "\n",
    "diff_img = generate_dot_image_3d(image_shape=[990, 610, 138],\n",
    "                                         dot_ctrs=dot_ctrs,\n",
    "                                         dot_vls=mn_diff[:, ex_mode],\n",
    "                                         ellipse_shape=[5,5,5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f34cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = make_purple_green_c_map(1000, True, gentle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5434f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_perc = np.quantile(np.abs(post_mn[:, ex_mode]), .99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2935ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "clim = [-plot_perc, plot_perc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b511c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_h = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7466c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_projs(horz_projs=[rb_horz, signed_max_proj(post_img,2)],\n",
    "                    sag_projs=[rb_sag, signed_max_proj(post_img,1)], \n",
    "                    cor_projs=[rb_cor, np.fliplr(signed_max_proj(post_img,0))], \n",
    "                    cmaps=[cm.gray, cmap], \n",
    "                    clims=[[0, 1], clim], \n",
    "                    plot_cmap=True, \n",
    "                    buffer=.1, \n",
    "                    dim_m=[1,1,ex_rs['ps']['z_ratio']], tgt_h=tgt_h)\n",
    "\n",
    "fig = plt.gcf()\n",
    "save_name = 'post_mode' + '.jpg'\n",
    "save_path = pathlib.Path(save_folder) / save_name\n",
    "fig.savefig(save_path, format='jpg', quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ffb8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_projs(horz_projs=[rb_horz, signed_max_proj(prior_img,2)],\n",
    "                    sag_projs=[rb_sag, signed_max_proj(prior_img,1)], \n",
    "                    cor_projs=[rb_cor, np.fliplr(signed_max_proj(prior_img,0))], \n",
    "                    cmaps=[cm.gray, cmap], \n",
    "                    clims=[[0, 1], clim], \n",
    "                    plot_cmap=True, \n",
    "                    buffer=.1, \n",
    "                    dim_m=[1,1,ex_rs['ps']['z_ratio']], tgt_h=10)\n",
    "\n",
    "fig = plt.gcf()\n",
    "save_name = 'prior_mode' + '.jpg'\n",
    "save_path = pathlib.Path(save_folder) / save_name\n",
    "fig.savefig(save_path, format='jpg', quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163c539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_projs(horz_projs=[rb_horz, signed_max_proj(diff_img,2)],\n",
    "                    sag_projs=[rb_sag, signed_max_proj(diff_img,1)], \n",
    "                    cor_projs=[rb_cor, np.fliplr(signed_max_proj(diff_img,0))], \n",
    "                    cmaps=[cm.gray, cmap], \n",
    "                    clims=[[0, 1], [c/50 for c in clim]], \n",
    "                    plot_cmap=True, \n",
    "                    buffer=.1, \n",
    "                    dim_m=[1,1,ex_rs['ps']['z_ratio']], tgt_h=10)\n",
    "\n",
    "fig = plt.gcf()\n",
    "save_name = 'diff_mode' + '.jpg'\n",
    "save_path = pathlib.Path(save_folder) / save_name\n",
    "fig.savefig(save_path, format='jpg', quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71bd0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
