import argparse
import pathlib
import pickle
import random
import os

import numpy as np
import torch

from probabilistic_model_synthesis.gnlr_ahrens_tools import syn_ahrens_gnlr_mdls
from probabilistic_model_synthesis.utilities import print_heading
from probabilistic_model_synthesis.utilities import print_info


# ======================================================================================================================
# Read in parameters
# ======================================================================================================================

parser = argparse.ArgumentParser(description=('Fits models for predicting behavior from neural data from Chen et al ' +
                                              'datasets.  This is a general purpose script which can be used for ' +
                                              ' transfer analyses - e.g., both when we look at performance when we ' +
                                              ' transfer performance for  the same and different behaviors.'))

parser.add_argument('param_file', type=str, help=('path to file holding base fitting parameters.  Generated by the ' +
                                                  'script generate_syn_params.py'))

parser.add_argument('-fold', type=str, default=None, help='The fold to fit to.')

parser.add_argument('-fold_str_file', type=str, default=None, help='The file with the fold structure in it.')

parser.add_argument('-subject_filter', type=str, default=None, help=('Comma separated list of subject in the fold '
                                                                     'structure to fit. If None all subjects in are ' +
                                                                     'fit. Subjects should be specified by their ' +
                                                                     'numerical label.'))

parser.add_argument('-results_dir', type=str, default=None, help='Directory to save results in.')

parser.add_argument('-sp_cp_dir', type=str, default=None, help='Directory to save shared posterior check points in.')

parser.add_argument('-ip_cp_dir', type=str, default=None, help='Directory to save individual posterior check points in.')

parser.add_argument('-save_file', type=str, default=None, help='File results should be saved in.')

parser.add_argument('-rand_seed', type=str, default=None, help='Random seed for reproducability.  If not used, seed ' +
                                                                 'will not be set.')

args = parser.parse_args()


# ======================================================================================================================
# Load the parameter file
# ======================================================================================================================

param_file = args.param_file
with open(param_file, 'rb') as f:
    ps = pickle.load(f)

# ======================================================================================================================
# Modify loaded parameter settings with command line options
# ======================================================================================================================

if args.fold is not None:
    try:
        ps['fold'] = int(args.fold)
    except ValueError:
        ps['fold'] = args.fold

if args.fold_str_file is not None:
    ps['fold_str_file'] = args.fold_str_file

if args.results_dir is not None:
    ps['results_dir'] = args.results_dir

if args.sp_cp_dir is not None:
    ps['sp_cp_dir'] = args.sp_cp_dir

if args.ip_cp_dir is not None:
    ps['ip_cp_dir'] = args.ip_cp_dir

if args.save_file is not None:
    ps['save_file'] = args.save_file

if args.subject_filter is not None:
    print_heading('Applying subject filter.')
    keep_subjects = [int(vl) for vl in args.subject_filter.split(',')]
    ps['subject_filter'] = keep_subjects
else:
    ps['subject_filter'] = None

if args.rand_seed is not None:
    ps['random_seed'] = int(args.rand_seed)

# ======================================================================================================================
# Create check point directories
# ======================================================================================================================
for cp_dir in [ps['sp_cp_dir'], ps['ip_cp_dir']]:
    if cp_dir is not None:
        os.mkdir(cp_dir)

# ======================================================================================================================
# Set random seed for reproducability
# ======================================================================================================================
if ps['random_seed'] is not None:
    torch.manual_seed(ps['random_seed'])
    random.seed(ps['random_seed'])
    np.random.seed(ps['random_seed'])
else:
    ps['random_seed'] = None

# ======================================================================================================================
# Load and preprocess data and perform fitting
# ======================================================================================================================
fit_rs, subject_order = syn_ahrens_gnlr_mdls(fold_str_dir=ps['fold_str_dir'],
                                             fold_str_file=ps['fold_str_file'],
                                             segment_table_dir=ps['segment_table_dir'],
                                             segment_table_file=ps['segment_table_file'],
                                             data_dir=ps['data_dir'],
                                             fold=ps['fold'],
                                             mdl_opts=ps['mdl_opts'],
                                             sp_cp_dir=ps['sp_cp_dir'],
                                             ip_cp_dir=ps['ip_cp_dir'],
                                             normalize_beh_vars=ps['normalize_beh_vars'],
                                             neural_gain=ps['neural_gain'],
                                             beh_gain=ps['beh_gain'],
                                             z_ratio=ps['z_ratio'],
                                             subject_filter=ps['subject_filter'])

# ======================================================================================================================
# Save results
# ======================================================================================================================

# Remove data and properties from the vi collecitons
for type_rs in [fit_rs['sp'], fit_rs['ip']]:
    for coll in type_rs['vi_collections']:
        coll.data = None
        coll.props = None

print_heading('Saving results.')
save_path = pathlib.Path(ps['results_dir']) / ps['save_file']
torch.save({'ps': ps, 'rs': fit_rs, 'subject_order': subject_order}, save_path)
print_info('Results save to ' + str(save_path) + '.')

