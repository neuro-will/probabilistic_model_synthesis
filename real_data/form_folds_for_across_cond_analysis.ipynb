{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e8364ea",
   "metadata": {},
   "source": [
    "This notebook is designed to be used in conjunction with the notebook \"segment_periods_for_transfer_analysis.\" That notebook breaks data for each subject into different sets, which can then be combined to form training, validation and testing data in this notebook.\n",
    "\n",
    "The idea behind the way we break up data is we want to do multiple analyses, each of the following form: \n",
    "\n",
    "    1) We identify a \"target\" fish - this is a fish we want to transfer model structure we learn from other fish to.  We also identify a \"target condition\" we observe this fish under. \n",
    "    \n",
    "    2) We identify a number of \"transfer\" fish - these are fish we will observe in conditions different from those we observe the target fish in. We want to transfer what we learn about model structure under these conditions to the target fish. \n",
    "    \n",
    "    3) We will from our training data in two ways.  In the first way, the training data for each fish consists of a different condition.  In the second way, the training data for all fish consists of the same condition as the condition for the target fish.  We make sure the total amount of training data used in both cases in the same. \n",
    "    \n",
    "    4) We then test the performance of the models for the target fish on the conditions outside of its training data. What we hope to see is that model performance improves when we synthesize a model for the target fish when the training data for the other fish is of the other conditions vs. when all fish have the same condition.  This would show our framework is transfer model structure across fish even when those fish are observed in different conditions. \n",
    "    \n",
    "To this end, this script will generate and save two fold structures for each target fish.  \"Folds\" here is used loosely, and should just be understood as an assignment of training, validation and testing data.  We generate such an assignment (such a \"fold\") for each type of condition we  observe in the target fish (e.g., if we have OMR L, R and F data for our fish, we can do three seperate analyses where we assume we only observe one of these conditions in the target fish and then the other two in the transfer fish). The keys of the folds correspond to the condition we observe\n",
    "in the target fish (so the different folds are not refered to by number but by string). We generate a set of folds for each target fish when (1) we observe different conditions across fish and (2) when we observe the same condition in all fish. \n",
    "\n",
    "See documentaiton of the function form_subj_group_fold() below for more details of how we assign data within a fold. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d41b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "465f6ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "\n",
    "from ahrens_wbo.data_processing import SegmentTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88965809",
   "metadata": {},
   "source": [
    "## Parameters go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7738520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = dict()\n",
    "\n",
    "# Specify where the segment table created by segment_ahrens_data_for_across_cond_analsysis.ipynb is saved\n",
    "ps['segment_table_folder'] = r'/groups/bishop/bishoplab/projects/probabilistic_model_synthesis/results/real_data/'\n",
    "ps['segment_table_file'] = r'omr_l_r_f_ns_across_cond_segments_8_9_10_11.pkl'\n",
    "\n",
    "# Specify the different conditions we want to test - there should be three of these\n",
    "ps['test_groups'] = ['omr_l_ns', 'omr_r_ns', 'omr_f_ns']\n",
    "\n",
    "# Specify the different subjects we use in the analysis - there should be three of these\n",
    "ps['subjects'] = [8, 9, 11]\n",
    "\n",
    "# Specify the percentage of data for each target subject we use for training.  (Note because we \n",
    "# balance data across fish, we may not use this much, so this is the max we can use.)\n",
    "ps['tgt_subj_train_percentage'] = .8\n",
    "\n",
    "# Specify the folder we should save the fold structures in\n",
    "ps['save_folder'] = r'/groups/bishop/bishoplab/projects/probabilistic_model_synthesis/results/real_data/'\n",
    "\n",
    "# Specify a base string to prepend to file names with the fold structures\n",
    "ps['save_str'] = 'ac_an'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d178470",
   "metadata": {},
   "source": [
    "## Load the segment tables and get basic information we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b2c006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_table_path = Path(ps['segment_table_folder']) / ps['segment_table_file']\n",
    "with open(segment_table_path, 'rb') as f:\n",
    "    seg_table_data = pickle.load(f)\n",
    "    \n",
    "seg_tables = {s_n: SegmentTable.from_dict(seg_table) for s_n, seg_table in seg_table_data['segment_tables'].items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e36fa92",
   "metadata": {},
   "source": [
    "## Define helper functions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "398b04fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_subj_group_fold(seg_tables, tgt_subj, tgt_subj_train_group, tgt_subj_train_percentage, \n",
    "                         trans_subjs, trans_train_groups, fold_types = 'multi_cond'):\n",
    "    \"\"\" Assigns training, validation and testing data for a transfer analysis for one target fish. \n",
    "    \n",
    "    \n",
    "    Here, the user specifies a \"target\" fish (a fish we want to transfer model structure to) and the condition\n",
    "    that we get to see in the training data for that fish (e.g., OMR Left).  The user also specifies \"transfer\"\n",
    "    fish and the conditions we get to see in each of those fish (e.g., OMR Right, OMR Forward).  This function \n",
    "    then assigns training data in one of two ways: \n",
    "    \n",
    "        'multi_cond': We see a different condition in each fish. In particular, we see the condition for the training\n",
    "        fish and each of the specified conditions in each of the transfer fish. \n",
    "        \n",
    "        'single_cond': We see the same condition (the conditing for the training fish) in all fish. \n",
    "        \n",
    "    When assigning the training data, this function will ensure the amount of training data in the multi_cond and\n",
    "    single_cond cases is the same, to enable comparison of fit model performance. \n",
    "    \n",
    "    This function will also assign validation data for the target fish (but it will not assign validation data for the \n",
    "    transfer fish, since we expect to be doing early stopping based only on the target fish).  The validation\n",
    "    data is the same condition as the train data, and the amount of data will be roughly equal to \n",
    "    1-tgt_subj_train_percentage (only roughly equal due to the discrete amount of data that is available) of\n",
    "    the amount of data available for the condition.  We try to roughly ensure balance in the swimming strength in\n",
    "    training and validation data by randomly assigning the top sets in the segment table to the train and validation \n",
    "    data (to see how we sort sets in the segment tables by swimming strength, see the notes below).\n",
    "    \n",
    "    Finally, this function will assign test data for the target fish.  The test data is simply all the data in each of\n",
    "    the train conditions for the transfer fish. \n",
    "    \n",
    "    A couple of important final notes: \n",
    "    \n",
    "    1) The segment table input is expected to be sorted by swimming strength (the notebook, \n",
    "    segment_ahrens_data_for_across_cond_analysis does this).  In many cases, we may not be able to use all the \n",
    "    data of a condition for training or validation (see below).  In that case, we use the data with the strongest \n",
    "    swimming signals (specifically, we use the top sets in the segment table, when sets are sorted by swimming\n",
    "    strength).\n",
    "    \n",
    "    2) Due to the need to balance the amount of training data across fish and the multi and single conditions, we\n",
    "    may not use all the availabel training data for a condition in a fish.  \n",
    "    \n",
    "    3) In some cases, there may be much more data for the target condition and target fish than there is for the \n",
    "    transfer conditions and transfer fish. In this case, we do not adjust the amount of validation data used (it is\n",
    "    always 1-tgt_subj_train_percentage percent of the original amount of available data.   We could have decided to \n",
    "    instead to increase the amount of validation data by simply assigning all data not used for training to validation.\n",
    "    However, it would then become much harder to make sure that behavior is balanced between the train and validation\n",
    "    data; thus we decided not to do this. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n_transfer_subjs = len(trans_subjs)\n",
    "    \n",
    "    # See how many segments are available for training in each subject, accounting for the data we need\n",
    "    # for validation in our target subject\n",
    "    n_tgt_subj_segs = seg_tables[tgt_subj].n_group_segments(tgt_subj_train_group)\n",
    "    n_tgt_subj_train_segs = int(np.floor(n_tgt_subj_segs*tgt_subj_train_percentage))\n",
    "    n_tgt_subj_validation_segs = n_tgt_subj_segs - n_tgt_subj_train_segs\n",
    "    \n",
    "    n_trans_subj_train_segs = [seg_tables[s_n].n_group_segments(grp) \n",
    "                               for s_n, grp in zip(trans_subjs, trans_train_groups)]\n",
    "    \n",
    "    # Determine the number of segments used for training - this is the min number available across all subjects\n",
    "    n_train_segs = np.min(n_trans_subj_train_segs + [n_tgt_subj_train_segs])\n",
    "    \n",
    "    # Form our fold structure for the target fish here\n",
    "    n_tgt_fish_segs = n_train_segs + n_tgt_subj_validation_segs\n",
    "    tgt_seg_nums = random.permutation(n_tgt_fish_segs)\n",
    "    tgt_train_seg_nums = tgt_seg_nums[0:n_train_segs]\n",
    "    tgt_validation_seg_nums = tgt_seg_nums[n_train_segs:]\n",
    "    \n",
    "    tgt_fish_fold = {'train': {tgt_subj_train_group: ['set_' + str(n) for n in tgt_train_seg_nums]},\n",
    "                     'validation': {tgt_subj_train_group: ['set_' + str(n) for n in tgt_validation_seg_nums]},\n",
    "                     'test': {trans_train_groups[s_i]: ['set_' + str(n) \n",
    "                                                        for n in range(seg_tables[tgt_subj].n_group_segments(trans_train_groups[s_i]))]\n",
    "                              for s_i in range(n_transfer_subjs)}}\n",
    "    \n",
    "    # Form our fold structure for the transfer fish\n",
    "    if fold_types == 'multi_cond':\n",
    "        transfer_fish_folds = [{'train': {trans_train_groups[s_i]: ['set_' + str(n) for n in range(n_train_segs)]},\n",
    "                                'validation': None, \n",
    "                                'test': None}\n",
    "                                for s_i, s_n in enumerate(trans_subjs)]\n",
    "    elif fold_types == 'single_cond':\n",
    "        transfer_fish_folds = [{'train': {tgt_subj_train_group: ['set_' + str(n) for n in range(n_train_segs)]},\n",
    "                                'validation': None, \n",
    "                                'test': None} for _ in trans_subjs]\n",
    "    else:\n",
    "        raise(ValueError('fold_types ' + fold_types + ' is not recognized'))\n",
    "    \n",
    "    return {tgt_subj: tgt_fish_fold, \n",
    "            trans_subjs[0]: transfer_fish_folds[0], \n",
    "            trans_subjs[1]: transfer_fish_folds[1]}\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaeed26",
   "metadata": {},
   "source": [
    "## Form fold structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86644051",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_cond_fold_strs = dict()\n",
    "single_cond_fold_strs = dict()\n",
    "for tgt_subj in ps['subjects']:\n",
    "    fish_multi_cond_folds = dict()\n",
    "    fish_single_cond_folds = dict()\n",
    "    for tgt_cond in ps['test_groups']:\n",
    "        trans_subjs = [s_n for s_n in ps['subjects'] if s_n != tgt_subj]\n",
    "        trans_conds = [cond for cond in ps['test_groups']  if cond != tgt_cond]\n",
    "        \n",
    "        multi_cond_folds = form_subj_group_fold(seg_tables=seg_tables, \n",
    "                                                tgt_subj=tgt_subj, \n",
    "                                                tgt_subj_train_group=tgt_cond, \n",
    "                                                tgt_subj_train_percentage=ps['tgt_subj_train_percentage'], \n",
    "                                                trans_subjs=trans_subjs, \n",
    "                                                trans_train_groups=trans_conds, \n",
    "                                                fold_types='multi_cond')\n",
    "        \n",
    "        single_cond_folds = form_subj_group_fold(seg_tables=seg_tables, \n",
    "                                                tgt_subj=tgt_subj, \n",
    "                                                tgt_subj_train_group=tgt_cond, \n",
    "                                                tgt_subj_train_percentage=ps['tgt_subj_train_percentage'], \n",
    "                                                trans_subjs=trans_subjs, \n",
    "                                                trans_train_groups=trans_conds, \n",
    "                                                fold_types='single_cond')\n",
    "        \n",
    "        fish_multi_cond_folds[tgt_cond] = multi_cond_folds\n",
    "        fish_single_cond_folds[tgt_cond] = single_cond_folds\n",
    "    \n",
    "    multi_cond_fold_strs[tgt_subj] = fish_multi_cond_folds\n",
    "    single_cond_fold_strs[tgt_subj] = fish_single_cond_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d535e8",
   "metadata": {},
   "source": [
    "Rearrange the fold structures so they are organized so that the fish is the first level and then fold is the second level - this will then allow the fold structures to be used seamlessly with our standard fitting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ece7b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_multi_cond_fold_strs = dict()\n",
    "new_single_cond_fold_strs = dict()\n",
    "for tgt_subj in ps['subjects']:\n",
    "    new_multi_cond_fold_strs[tgt_subj] = dict()\n",
    "    new_single_cond_fold_strs[tgt_subj] = dict()\n",
    "    for s_n in ps['subjects']:\n",
    "        new_multi_cond_fold_strs[tgt_subj][s_n] = dict()\n",
    "        new_single_cond_fold_strs[tgt_subj][s_n] = dict()\n",
    "        for tgt_cond in ps['test_groups']:\n",
    "            new_multi_cond_fold_strs[tgt_subj][s_n][tgt_cond] = multi_cond_fold_strs[tgt_subj][tgt_cond][s_n]\n",
    "            new_single_cond_fold_strs[tgt_subj][s_n][tgt_cond] = single_cond_fold_strs[tgt_subj][tgt_cond][s_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdf28b1",
   "metadata": {},
   "source": [
    "## Save fold structures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feec9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tgt_subj in ps['subjects']:\n",
    "    multi_cond_folds = new_multi_cond_fold_strs[tgt_subj]\n",
    "    single_cond_folds = new_single_cond_fold_strs[tgt_subj]\n",
    "    \n",
    "    multi_cond_file_name = ps['save_str'] + '_tgt_' + str(tgt_subj) + '_multi_cond_folds.pkl'\n",
    "    single_cond_file_name = ps['save_str'] + '_tgt_' + str(tgt_subj) + '_single_cond_folds.pkl'\n",
    "    \n",
    "    multi_cond_path = Path(ps['save_folder']) / multi_cond_file_name\n",
    "    single_cond_path = Path(ps['save_folder']) / single_cond_file_name\n",
    "    \n",
    "    with open(multi_cond_path, 'wb') as f:\n",
    "        pickle.dump(multi_cond_folds, f)\n",
    "    with open(single_cond_path, 'wb') as f:\n",
    "        pickle.dump(single_cond_folds, f)    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
